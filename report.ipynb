{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DBaudry/Graph_Matching/blob/DB/report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1J3HaX6QTnm"
   },
   "source": [
    "# Compress Sensing - Project report\n",
    "###* Dorian Baudry, Alexandre Filiot - March 2019 *\n",
    "\n",
    "https://v2.overleaf.com/project/5c76c42c2a7f6e16e20a03f8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9iJBJ47RGFiA"
   },
   "source": [
    "## Abstract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK5dIMOlEEnf"
   },
   "source": [
    "As part of the course on compress sensing, we studied the 2 following articles: \"Balanced Graph Matching\" from Cour et al. (2006) and \"A Fast Semidefinite Approach to Solving Binary Quadratic Problems\" from Wang et al. (2013). We mainly focused on the first article... (**à voir selon notre état d'avancement**).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5O5KkPKS2j0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from copy import copy\n",
    "import cvxopt as cvx\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQt4pMJxdMJ_"
   },
   "source": [
    "## Introduction \n",
    "\n",
    "\n",
    "The topic under scrutiny is about graph matching. Graphs have been widely used in various computer vision applications and machine learning for their ability to conveniently and efficiently represent object. Once graph-based representations are constructed, it is essential to know how to compare graphs. Whether in order to quantify the similarity between the latter (for applications in supervised or unsupervised classification) or, mostly, detect similar parts (identification of similar interesting patterns in the data). That is what graph matching aims at: seeking a mapping between vertices of two graphs which optimally aligns their structure. For example, one can cite the task of 2D and 3D shapes matching or deformable objects matching. In those applications, a test object is compared to a set of template ones. Each of those images is fully characterized by a graph whose nodes represent feature points (like spatial location, orientation and any useful image feature descriptors) and edges represent relationships between feature points. More broadly, the features could consist of points, lines, shape descriptors or interest points, depending on the specific application.\n",
    "\n",
    "Classical formulations of graph matching problems concern one-to-one correspondences between graphs. However, it is more accurate to consider at least one-to-many correspondances as graphs rarely match perfectly. Indeed,  a given point from the test image can be related to a cluster of nodes in the template image graph rather than only one point. For example, a point from the test image can match a set of points from the template images depending which characterize the same part of the image but with slightly different attributes due to noise or object view. One-to-one, one-to-many or many-to-many matching problems can be formulated as a discrete optimization problem where the objective function to maximize in the overall similarity, or affinity, of matched edge attributes. Despite some restricted settings where this problem can be solved exactly like bipartite matching, this combinatorial problem is NP-hard for general graphs (the original proof can be found in \"Computationally related problems\" from S. Sahni, 1974). As underlined by Cour et al., most of the recent literature has been focusing on the development of approximate methods which are able to find a \"good\" solution in reasonable time. In particular, efforts have been put in solving a continuous relaxation of the discrete optimization problem such that Semi Definite Programming, Graduated Assignment or Spectral Matching, methods that we will discuss later on.\n",
    "\n",
    "The main contribution of Cour et al. is twofold. First, the authors propose to incorporate some of the one-to-one or one-to-many mapping constraints as affine constraints during the discretization step. In order to do so, they use a problem called Affinely Constrained Rayleigh Quotients. The second contribution is the bistochastic normalization of the graph matching compatibility matrix which aims at improving the overall matching performance. \n",
    "\n",
    "\n",
    "<center><img src=\"http://specmatch.gforge.inria.fr/SpecMatch/illustration.jpg\"  width=\"450\" ></center>\n",
    "<center> Figure 1: Example of moving objects matching using graph matching. Source: INRIA/INPG. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djbuNwtwdD9a"
   },
   "source": [
    "## Problem formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgakUWvzdTFK"
   },
   "source": [
    "Graph matching problems are based on the notion of *attributed graph*. Namely, an attributed graph $G$ is characterised by the triplet $(V, E, A)$ where $V$ is the set of vertices, $E$ the set of edges and $A$ the set of attributes. To each edge $e=ij \\in E$ is assigned an attribute $A_e \\in \\mathbb{R}^d$ with $d\\geq1$. Vertex attributes are spectial edge attributes, denoted as $A_{ii}$ for vertex $i$. As said earlier, $A_e$ can be a real number or a vector. In the case of image segmentation, one can see nodes as features points (or super-pixels) characterised by their location, orientation or any useful image feature descriptors (here, the $A_{ii}$'s). An edge $e=ij$ indicates that their exists a relationship between points $i$ and $j$, which is described by an attribute $A_e$ related to their relative position, orientation, etc...\n",
    "\n",
    "The question is, how can we quantify the matching between two graphs ? Now, we need to introduce the notion of *graph matching cost*. Let $G=(V, E, A)$ and $G'=(V', E', A')$ be two attributed graphs. The goal of graph matching is to find a mapping between $V$ and $V'$ that best aligns the attributes between edges $e=ij \\in E$ and edges $e'=i'j' \\in E'$. We are looking at maximising the *graph matching score*, defined as follows :\n",
    "\\begin{equation}\n",
    "    \\tag{1}\n",
    "    \\epsilon_{\\text{GM}}(M) = \\displaystyle \\sum_{ii' \\in M, jj' \\in M} f\\big(A_{ij}, A'_{i'j'}\\big)\n",
    "\\end{equation} where $M$ is matrix of correspondences:  $M_{ii'} = 1 $ if their exists a mapping between vertex $i$ and $i'$, $0$ otherwise. $f(\\cdot, \\cdot)$ is a measure of similarity between edge attributes. As a particular case, $f(A_{ii}, A'_{i'i'})$ is the score associated with the match $ii'$ which is a vertices match (and not an edge match). From now on, we will note $n=|V|, m=|E|, n'=|V'|, $ and $m'=|E'|$. \n",
    "\n",
    "At last, we need to rewrite $(1)$ as a more workable optimization problem. The first step is to flatten the matrix $M$ into a binary vector $x \\in \\{0,1\\}^{nn'}$ where $x_{ii'}=1$ iff $ii' \\in M$ and $0$ otherwise. Then, one should introduce  *mapping constraints*. These constraints are related to the structure of the graphs matching : one-to-one or one-to-many matching. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjTirk4MYBkA"
   },
   "source": [
    "We propose a simple representation of the graphs in our algorithm, using a tuple containing three objects:\n",
    "* Size of the graph $n$, each nodes being assigned a number $i \\in [1, n]$\n",
    "* List of the edges $[e_1, e_2,..., e_m ]$, with $e_i=(e_{i,0}, e_{i,1})$\n",
    "* Attribute matrix $(A_{ij})_{i,j}$ representing the attributes of each vertice (in the diagonal) and each edge in the graph\n",
    "\n",
    "Using these objects, we can build the compatibility matrix between two graphs with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rG0ozoVlZMij"
   },
   "outputs": [],
   "source": [
    "def get_compatibility_matrix(G1, G2, func):\n",
    "    n1, edge_1, A1 = G1[:3]\n",
    "    n2, edge_2, A2 = G2[:3]\n",
    "    W = np.zeros((n1 * n2, n1 * n2))\n",
    "    for e1 in edge_1:\n",
    "        for e2 in edge_2:\n",
    "            score = func(A1[e1[0], e1[1]], A2[e2[0], e2[1]])\n",
    "            # each of the four representations of the edges is assigned a fourth of the score\n",
    "            W[n2*e1[0]+e2[0], n2*e1[1]+e2[1]] = score/4\n",
    "            W[n2*e1[1]+e2[0], n2*e1[0]+e2[1]] = score/4\n",
    "            W[n2*e1[0]+e2[1], n2*e1[1]+e2[0]] = score/4\n",
    "            W[n2*e1[1]+e2[1], n2*e1[0]+e2[0]] = score/4\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            W[n2*i+j, n2*i+j] = func(A1[i, i], A2[j, j])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HoJSQKQ6ZX4C"
   },
   "source": [
    "Note that we consider undirected graphs in this notebook, so for any symmetric comparison function a single combination will lead to 4 values in the compatibility matrix. For this reason, we decided to weights these 4 values by 1/4 in order to stay in track with the initial problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHuqHMLvdTHq"
   },
   "source": [
    "### One-to-one matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IH7QYI3fdTLS"
   },
   "source": [
    "In this section, we focus on the one-to-one formulation, i.e. $n=n'$. If $n \\neq n'$, we can always add dummy nodes with no connection to the smallest graph. For this particular setting, $M$ is a $n\\times n$ matrix. The one-to-one matching constraint can formally be represented as $M$ being a permutation matrix. Indeed, $M$ is a binary matrix verifying $M \\mathbf{1}_n = M^\\top  \\mathbf{1}_n =  \\mathbf{1}_n$. Using $x$, we see that those constraints can be written as  elementwise and\n",
    "\\begin{equation}\n",
    "\\tag{2}\n",
    " \\displaystyle \\sum_{i' \\in E'} x_{ii'} = 1, \\hspace{2cm} \\displaystyle \\sum_{i \\in E} x_{i'i} = 1 ,  \\hspace{2cm} x \\in \\{0, 1\\}^{n\\times n}\n",
    "\\end{equation}\n",
    "For this first case, problem $(1)$ can be rewritten as an Integer Quadratic Program (IQP):\n",
    "\\begin{equation}\n",
    "    \\max_{x} x^{\\top}Wx \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} (2)\n",
    "\\end{equation} where $W$ is a $n^2 \\times n^2$ **compatibility matrix** with $W_{ii', jj'} = f\\big(A_{ij}, A'_{i'j'}\\big)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8vfrjX9aXWzo"
   },
   "source": [
    "We ran all of our experiments with this problem. So we propose here some functions to build the constraints matrix, that will be used for instance for the SMAC algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mb-t1nDTXpx4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.]]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_1t1_constraints(n):\n",
    "    \"\"\"\n",
    "    :param n: shape of the affinity matrix\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_tot = n**2\n",
    "    C0 = np.zeros((n, n_tot))\n",
    "    C1 = np.zeros((n, n_tot))\n",
    "    b = np.ones(2*n)\n",
    "    for i in range(n):\n",
    "        for k in range(n):\n",
    "            C0[i, n*i+k] = 1\n",
    "            C1[i, n*k+i] = 1\n",
    "    return np.vstack((C0, C1[:-1])), b\n",
    "\n",
    "n=4\n",
    "get_1t1_constraints(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yW21uqelaMK9"
   },
   "source": [
    "We also propose a function to compute a random permutation matrix, that will be useful to get a starting vector for the Graduated Assignment algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIMNOpDCabA2"
   },
   "outputs": [],
   "source": [
    "def random_permutation_matrix(n):\n",
    "    \"\"\"\n",
    "    :param n: shape of the squared matrix\n",
    "    :return: nxn permutation matrix\n",
    "    \"\"\"\n",
    "    r = np.arange(n)\n",
    "    np.random.shuffle(r)\n",
    "    m = np.zeros((n, n))\n",
    "    for i, x in enumerate(r):\n",
    "        m[i, x] = 1\n",
    "    return m.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EsNVhTGjdTPa"
   },
   "source": [
    "### One-to-many matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdsaijYOjsOt"
   },
   "source": [
    "Here, we suppose that, for example, $G$ has less vertices that $G'$, namely $n < n'$. Our goal is to find a matching that associates each vertex of $G$ with one or more vertices of $G'$ in such a way that each vertex of $G'$ is matched to a vertex of $G$. Now, the constraints are modified such that $M$ is a binary matrix verifying $M^\\top \\mathbf{1}_n =  \\mathbf{1}_{n'}, M  \\mathbf{1}_{n'} \\geq  \\mathbf{1}_{n}$ and $M  \\mathbf{1}_{n'} \\leq K  \\mathbf{1}_{n}$ where $K$ is the maximum number of matches from one vertex of $G$ to some vertices of $G'$. Using $x$, the previous constraint can be rewritten as: \n",
    "\n",
    "\\begin{equation}\n",
    "\\tag{3}\n",
    " \\displaystyle \\displaystyle \\sum_{i \\in E} x_{i'i} = 1 ,\\hspace{1cm}   \\sum_{i' \\in E'} x_{ii'} \\geq 1\\hspace{1cm} \\sum_{i' \\in E'} x_{ii'} \\leq K, \\hspace{1cm} x \\in \\{0, 1\\}^{n\\times n'}\n",
    "\\end{equation} \n",
    "\n",
    "For this second case, problem $(1)$ can still be rewritten as an IQP with different affine constraints:\n",
    "\\begin{equation}\n",
    "    \\max_{x} x^{\\top}Wx \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} (3)\n",
    "\\end{equation} where $W$ is a $nn' \\times nn'$ **compatibility matrix** with $W_{ii', jj'} = f\\big(A_{ij}, A'_{i'j'}\\big)$. \n",
    "\n",
    "____\n",
    "From now on and for simplicity purpose, we will rewrite problem $(1)$ as\n",
    "\n",
    "\\begin{equation}\n",
    "\\tag{4}\n",
    "    \\max_{x} x^{\\top}Wx \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} Cx \\leq b, \\hspace{2cm} x \\in \\{0,1\\}^{nn'}\n",
    "\\end{equation}\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ogs2Tl53dTSi"
   },
   "source": [
    "Problem $(4)$ is NP-hard and one need to relax some constraints in order to approximate the optimal solutions in a polynomial time. State of the art matching algorithms uses continuous *graph matching relaxations* to do so. They relax the original IPQ into a continuous program ($x$ is not binary anymore) and then use discretization method. In other words, each of them relax the 0/1 integer constraint $x \\in \\{0,1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SX6rWJZ5-Oz6"
   },
   "source": [
    "<center><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAACCCAMAAAB8Uz8PAAAB11BMVEX///+S0FAAsPCbu1nR0dHHx8fKysro6OjNzc3f398AAADj4+P4+Pjt7e3Z2dn7+/uO0UWnvJXByLqAgIBaWlp6Y5j18/jz9PKHwUqYtX55rUKLzkCR0UvT1dN2qEHFutOYmJh4eHiOd6zp5uymlb2svJ6Py05/vjivn8Nra2unp6eKioq/v7+BuEekvI9wqS6goKC2traTtkj/Z2f/2dn/q6v/oaE2NjZCQkJxcXFPT08kJCQuLi5gYGDuy8v/c3MAmNwVFRW4AADemJgApunCrtSux3z/AAC90peYc7ne8vzCERFYAJN4zfX0+u+13o4AmM/N1ebA45/029vX7cOOq1HC5/qq3fiWp4lcptpqRZSaoJXPXV1cgzJnkjjr8d/g8dHIQEDmsrK0xt/Tbm7/QUE1uPHM6LKuksel13Pl3O3S7fukwWn/Hh5yikKa1/cAcpv/i4vaiooAOU5fcjagfb63g4GIsdm2S0hpH5ylnLF5WZ9vOnmKd6Og1Wphw/PLq6q1eHe4Pzrkelv/MDD/VVU/TCR4kUWDUKt4PqWOYbKauNoAGSNIk80AMEJmeLYAd6OMqdE+WCIbIQ8AT20wOhx2drGYsGfFKirXe3uGnXPWKT7cVyNz+kqHAAAZQklEQVR4nO2djX/TRprHh0SyXqyXXu21uZaAXffYWhaHlUL9kji1Q6CQhYQQSEgLjUvYBAJtKKWFLtdC2W1py2VbaHe3vbs/9uZNsjSSbTmxYxP4fSCRxpIiz1fPPDPPvAiAl3qp7iolgKSqgjxQYv2+lRdVFQnIlYouA2W837fyogohEADHAaXQ71t5UQURjFVycOMlgn4JWQHe2EUILEvFv8tRCQATANW0hJzWyRWUCLmQgn4mOZKoapzQzdu0BRGUC+PKLkKgyHkjhTa4ElcEEvxaRtnQxHTY83O1Qixaxlca4+BvmS8BIMqFlJXTsr244bhEN5Jjvbj8zimRyZCNVApEdSubNfIGNPCUBRFkeYV+PT2TUYLOnlmeoVsR9CimBME0OT4GL8DHUkkAeJj5MZ0WGET68nIHt2elmn6kOlvNjMzMdfCX+qW5zWq1uvkEbeaMaCWraJqas0DaLMAcN+JGEude4ik8qvo0w55dvzk6Ojq8hrdTeakI6+eCyWtGHpT4tIhSI3IB/ZYdfssn4CmjJ2fYSwVLGpdzsa0rNyab286iHutJdQhpahNmEScLZjYSi1kpA3DjcRDljJiiKDXIiRw1VJ3znn1ydBhp9KYOd8wiEGDxYxaKMVieRbKkrs6TIshBUCenDI+GtASjZkW3LnE8luxORvVMKzRvh4Y24V6kksXelIfFf4kDRkrLVkwuCxLOUVWPHZyn2Tk8fALtpsfGqd9ATkBGZQAXH5HLKVj22AXRsnPKqB7uFlULKG7pCqMWCbo4gk/uRlb1SpswW3++5XvAyQNMWv0xETzFhnIW/XzqPhtl54Xvhh8/o8+07uSqneMxWCfCFmL79BPwlE/+cWf4l+HRk6HuMGlJmkcRy7uv8SaTAEtCryy1/d/pl+amYK7e+hU/4HebH4ZATd36O2JQdSXjMuVxbfjOheFhJj/tqorNJGpvYGrD8uPH8HeoW0yydeKkxCSorC8W2ByPDjCCFYTgLEHw01tNhRAMnf0MI0g0zibl0C+4WPnXqTdC6SI6+M4dXBKFukWKQMEMkZmpBAEpXHBC1JWAjhMEdwJ4fhD8882m+gkj+PVWIAKZIDgQTv9CBdF3wx0hSJZEWEPT0yasdGEE+UIOZHk9zcNKHEagZjVQ4YxCDMQsjCBXSIGyho4rmYONIIP87K+/4lL+SfPDkBWcvfXZz9Rr28Ku9Q5+pEMW7KQgunMHM7gZ6gSIwCiboAisigHKCkYgqrIAE+IWKBMrMIoReASXlCXUMoQIREFWy+g43FQcZAQ4cwPqOnMrc+5dYiwI1JQH1LCjsFVMuxqLTjkf6gRUEKVx3R5WlVFphAoiDbt72HzBCbAgquCaXJTUAlBBFME1CokkDDSCjF3dnHJVdVY2q1NT1U0XBIfUpqcm6dQwQxsB0B1q4YzAiwAJIlBlnKcQAU5ACFA0KlkjTgAiEHA7RK2RvB9oBHajq/rP+2/ZpfwTth22/sb9n6ZIAy7hPZu2s8ITAGBmeLTRmgshiMAsVGAu88Uy9swq6qdBsUO+SGJEEIE1loW5PxbP4bggRCBnc/AUctygIwCJJ5vVzadzMJ/fJxDmGu0wvJ954/03E2BlqVrdXPGdPXMS5uiJTkI+0IvfhKfUwx4NEUicCPMwKoo4JyECjougBI4mRIHGReBTr+FkjAAeAVvFIzRhwBE0hCAotNC5dYt66MxXCEAf5WsXqL52QZRJENiGwnODgEDA3uHs2f9Gzncz0W8AoZpmPgTPU9PMJwiBuF4Zt9bef9MXG91pKTwnusVFfAmRdgn8oIfqvDqAXcHfsfvd7DuAF1O4IPoMRyOetj+697p4mNEHGueRaHn3OYPZ56x+f4cO9WTKqRHNtT+69/q3V/Z49Mqr7BGst+DYA3wJgy67HTbVxgjEPPpuqgDisDGaByNwW80pIB6ywh8sQQHuh5yHCPa1QaDvPgTKJnYH1RZBIyw+B8Y4kDXBGO6jHdNAha/BBtK2EMRzgHftRjCCfS8aAtg6e7q09KStK4YIjBzqnCEI0HZU2yYCXpbViGufIPjw8sEXDUE4QQRJWSrZCNSaVkLJ20KQShkW6u1HtUgU5cEI9u7/8Nm+lwgCBBGAcjFiIwDFIh4ysb2CKB9BBVFOFkBK1giCV/Y+e/YSQaAQAhOF4ykCvL1tBDxCoI4LQC1LFMGHzy6/RBAo0x7UL7u23SOGtiKCAIwJ0Kok2xfsP3TopS8Ikm7nddK1TYrxrctGoEIEURvBC1cp7asIgsr4mF4ah6YQCdM0Y+N2uwFBLt/rv5BvNsyQWoEtiODia/s9OvyBGPGIN7wJIrMfiTxvAQogyrV0llUp3VSxXHOlmkkusiFmIgaBGKIg2o1WYNUslZXQfNwmM9rNIzZg5gTO5Fyw14YITG3Elma9qL5A6WhWx1ZkBdsAsQLX8NDgGFHObSi7E0Ef5fcFAQhiljtTu4ogk+lzLyESzzPezTIZ9+bzdyESLPaqZrClpSJhEBTjronGnSHQE82bjvqTanWq2jY+2XP5vkDUV9P3HSKyCRE2QWKLfl8XMFFKRAiKcgmYstQUQUR1TTTuBAEaCFJd8o8EwXIGVbFjdXZavi8g+Tq/2+e4HwHL0TcQgoggUAQZRIpNEaTT+UrjlPAIEktTQ4Hjocinzugdz8jZPgjebzKnAyWlgALOfIhATBsAGBwwyIA2EUjpFACmCXhSIMCcEg2g5nKKULYT8mkNGGkOjOHnHyIw0hFgpU2QtUdkBYkgALmYO0DBIuB5d30qNALdNXwzoD62NNTQUri86pHg/ZZkBaRlVSniBIjAEGXJKBqgTEboiCCijvF8OY3mfyBFABePAzESz1kGTVCtlAyRyTq9SBJWNmGCKdPFCloiMOKgBwGKuy3zeG7K9XG1rwMX0P2iUFtNVcmjggoiHaak8oBWJUX4wBd0NHWG5iPMKQ3lWtwSnARgVFD0lM4yggj4Ug4PtCXlWisESblcVGMyNMJQAYqQCDLVlnn8ZMitvrpkjEBHCGgCQlA0nWG1ACHQubIBSxU7IYJmldGH106Q4EUEJ2wKEQi8nNRrdoOgtS9QkgBPEcMBCq8Of+AdJSRGLGbYkMEcIJIARZs8puXQz2f7XxJxaKKqBUTZjqxABPGKGY1WSvZAQRFYYtFQY2U7P2G5kypIvGzyjQTZMBU5b9IqoKQoBkRQi5mUbGtfYKubVrDkQYDzWJ+eXlhY3DiDRMshQmDofz9+9+iRVtnUS8H7NYw8+m/nngosIy9xhmF/VxGMpCwg5Q27ahQBQt5A040tJ0GFF0D/qRlAK7BSEroq5dgCgWvGZDdHUHgRDKFs31hcXLgxPa27PibzXYYegCPvvP1enzj0vVJqNoJOUjdjRAFW4NYTDwLSdND7wyEEAt8hIRB01DRzFCZSihBw7ss3QdDGF1BvTRC4GwZb4bCtzlsQERhFNCZBtdROEwReYhK0JgEKvy8IgaAcS7kSwtSIpvy1zrsuX+CbAdwJhzpa4iH8DAq/1PbLCkidJ/gVHKwmMaLyWBrwzQMUTO5onkVGmrcL2rS99AaiTf+n+IgwHPQTdOrRiVZHDbCoFSgy4Ju3jr1CCCLuXrhmCJQ2EYgzdvxiqdUIhHYcbjrzGUPOphs05TgyjijVKkDhFUQQjbmdT/MYkR2hCBy1P71Io3ghRjMjDh8HcmhMKe1oCt4AKcURXyALPRlBsYKW/mkSjV5YwFcLf69BHGYaBEKsdKIYEd4r3M+d+XdW/9M24QPmShHDd2WTSTCb1IgQArVYLAInQNHdjstE0z6Zxek2GeZW0s5dhgNdnOYfF9CiBKP1FldARWdA9yQy58wf9zE6xCa8xuy/8h/shfw127CVUmwFOgpL6crOjiPa6MAAlG+ueG7B4XCOPP+fXHiGfrUoiRQUfVBGfOkEgfcr7zn4GpOwZz+z70fga7yFbppxPQtQNJHz8J9h7/AKUFC5NIHQ6GiY8bwyP0E+e/jonu9CmMP/DVMraCzTFKzS+LiCEURgeStKwKKBhcFAoCRtoe77gDBdpxOdWq2Npg89oFsEwbGrAPx2Bcz/Bq4em58EH/0OJudh8uSVK5PwB0xBit675zUDRycIgu8IghZWYGXFKEKQqlkgXzNAhT5INoJD7gzeaQTuFZ7CBCi2ZwWLC6u0ACIIJibB/ORVcOwSyvoJ+OBPfISS53V9XpnUCQ+gPLyqTgRejlaICIKWy2yg2UjICtDaMSkDNMJt2Bc8u/yL63v3syAKG6DwqCMEq2dWFxemUWFEECiT6pWPJsGlK+okgP+uHpvA7vu3iYnJeZj9l47ho74ItgH3wm8IQas1EONKA0HO6QewEey/LPfRCrYQoPAK53hKZRKCNb0Kbqwu3JjGzQKs365cmphMTKoTFAFNnZj4E/r9+238bR41veAJF4KW7WOKIJnN60q60RFLEByU9/QZQTSuglwhvx0E8SiTECxU7Zo+s3DDbhYAcPt3aAPHJkELBHpTIwBgzdU0aznInCKwYmnJjKWdW6RWcPnO5f4iSNUEwKFut60iKJTlcAiwNhACu2Y0MfkbODb5O/QIDoIrlxwEl1Dm8/7qkKPZRlE023ItVrsgYkTdMazq9xcBnuJhFrdsBVoRlDtAgJsETrPg9gRQb8Nif3Jevw2uIK8La0k2AuSOpUfNV+A+vwxm8Fq4aDHc663+JkbQrGnG5jiLYN9+Nle61zTLcfYUD6mmbxlBtAZqnSBAYpsFsESyt5BZTPwJ1lZR6QRrpMGVIaxZfEfL9WUEdOZci7+HEfjqz3ilgMxhpiK+/0Mm4TU24dBFZgj1iH8NggiTwAf3F+RG8CAWOabIpZyw5YIoF8+Fc8cN+RDo843teVRBBWhyO5BaEah7q6Fr9eaHtrQC5jvvOcQk9MAKaIzJRsBxEZ1DyzztYIDChyBYDx/Nt/h0NnC/sbS6S619gVc74Qvo0uA6ReC+oe5N8VggHnd644YOUEtgYWF6oxGaC4VA++Zqq2rOzBqToM/iVchGR4dPshEoikDnoLkmk4CnWdb/AAWDQPRPdHqNDcvyTMQ34osAk/DL6sbCBvq9cePMIlidBtNDC9MLTsZPbwTejys3k9LDq5daFEJQ/rK/vnaTdqKxi1hSBNmsnLRkA5To1+4bAi2SFBTURIQITHe4B4XpmLBsWyvwWTe2AtgIg1n+4MHCqjL9AKzC7z+0OK2s2sfcWGDPakgRv7h67969q1dalUFIbDkEyMKsgW1lpyCSBSVlALt93DcEpgFzG42W9ltBt3wBRLDxYBoWPqs6GEL2oKze0HUHQfPeAuXhvdsTQpjZ1Gv+Iv+kq7Hs7ci0EeTSAQGKfiAYLxcqAQi66Y5XNzYeKBDBg2mwMTUNzuhDCzem7TBp894C7t6xsFOp/Ubg7USruz+iCPAg0NQAIEiaPI/70QgCK8bB/3yXu2wWFvGjvLEIlAUAMx/iWHA8AHIKOufn8PBeu9IHfRl8C+frvg/OuxF4Y9cUQbk8zhvFghNPHxR3nDdkkLe2EaBolaDjeBwZxbjo5DlEIL35BzXplfrF1WQIaff/IlAjWP7a/bfc5RBTEg1apbRcKEIVnEqpOE4Wpt65dsEZMHf//ld/YPVfvpRAfXX/fmYZN8vOXXe3zk54EKA3NlSIOgtQBCDoetOMPk22FSRlFSjyjqxBMXd3aenuHLaCuft/URMePbyaCKXMV29kqCf4GrjNwG8FEpEdoIiwQl4hc3ivV4f2Mwl7P2QTLjIzwwX2FUACrzEpWquCSE6Zipwzkz1HkNiki3HP4dLpuNcXRB+FdMSZA3ZAqL5n9pWZ+rl6vY4/aOcL/FaAyg8fgr1tEfzxIjum1PQNTPWNKW0RptPpwPheDGLxZp0zvm4qoFmgN+kfDtY5XCOdXQZra+eXbc+se2pEqHFWStHje+0LthwpjWk7OYKiMf8vaIgj5+sWCBiC5CS5aqTnKA/gGVxHvHHUpHfjBCiSOEARocn9rxExCMSgERTsyhbWiGdXM9i4bbMRFCvu0e7+1yl94YpGrF97KwFOHV//EXwOCx34Qz+dOH4NnF5/63NywJor/lBvIGgMMaWtY1OmLw2lCGIpWR+IAIUjiMD0OqceFkSbbgRV5qoTgqtFkDh9/No6OJ2Ahf6Bdbh/ILP+JVhfT5zWE6fJEd5mmatWZA+0HqZUdLM0joJWdkEkyDoKUNjrD20DQczdTdVNK+gdAjrX+xaZUjDFRCi++ObeJWdn/XQG/oC57lgBJHL82nG4fRohAdT9BglPN7jZgKLhQcs2AjFbVLoToLBKwD0Zp1sIeuqOM1NuBEPvvf3OEVeNSHr0kat/8vPTp8DxH8H6D+DH43AX/zh+Cn3yPUISFKBz32Jjk5fL5E3E9ggKULC6g8DwvlJ1mwg0QwUSmsO8Ewjo7LKpuSNH33UPlPYOk1j/4RpBcArl/ikGwTLbUdBUql0vsYPV4yVgFLoRoFBrBfcX3SaCXF4GpVyvW8e6e3YZnQyuH3nn24///CkKS7vveH0dnLp24HtiBfo1txX8gBC0NgK3cMNMkwYvQOGIIBCMLDyi5wGKJQ+CRnriyqd/fu/bdyYaFen1H778Uc+cBuvfo2rRafC5gwDWjNr003tVIQvNbTtA0RaBv13QEQI+VwYAGWdvEeBlJ87KpBxiV8iZP/rp3z72uocv15FPPnDtON5L/HgN/jzwAwjsKGgrjIB9ZSoeRQsRvM7ocNuELluBEk3Kajyn9iZS6pJrYZDgGX7IPfzt3aO0droOyxzYGFine5+jZhmuo4YvhxrCCPx3hqwgao54JVpMwojhS2BZGiMsXJF9RW7wIBaMQC+VTZAtVaI9RqDbE/zYd+Z5j2q4hyYK6ChoKrp0ZUtf4Hv9ke8rhliV67kIUKAus5UqhDDVfi005B4+/vadI4H9l50YgUnkRQD5S7RZhRGwo/X8PqP9AgjdDFDsPeTR3g8krzSTSbCYfSk4QEE7LedWVuZCTnGaP/oudg9Mcj3c2zqJHIYUASdbIDYm6znXLJvuISi6rhQagQRM97o20AoOerXv1SSzhqro3U3y7AG+20NaCDl2i9WRo2+73ANU/eTJk/XQp/NyidwORaDFLIhF5uz1DruJQOLLW0PABijaFUQd+YLMypMV3ABYbDduqJUU6B7eg+4hgXoERtEgoeF66JO53BhqDLunePCN1Q67iECVLXn7CLrsjjO4h2Zqcw714W9X2D381XnZLS2N6tdnZ87h7dll6CPOnYdNhvOzs+B1pzeNT8soJucgMIE21rhqFxGIFbANK0CTXiXQbQQrdg9N9UGLgVudyNUrRkbLLX8N9JnrYGZmBuwBB2eWZ1HYGiJZPgeu02B1lrgmiiAl17TCeMFZ2XxQrAC9SKVSGusygsY7bIemuvPKNk+nGOqch7ldn4Us1tbWlq+jn3WUuPY1qjOdw9tOPrSqlHbJF2im5qrBdYYgOQ5vQqp1GYG7e6Aa+Nc7FTGCx48ff2KbASx31mAxdG52FiKYuU4meZDMJz/JcnpiywBFnyulkj3LxiiWuovAswpmd8yAjFG5cIHMccW989ev76mTD/cAgJ9+aAtfo0LoOi6p0mQMOUVgsus2qaiU6nPTTHJepAJkrasI3MuUBvVTbkGkV/LOncC59tdp4GiWtjoOej8mCNiXEgjIKUQtZmi4yQ4Wj+TbJrDLgPAGswwIbzUJUGAE8fExtSjHumsFbdam24oIgk/uDAchmPHG7nQmlNeqIBoEK3Dd0CAjOOFB0NnyQ4w7TtIMGhhf4LpO12JEPSiIiDu+QxC0XPrGL6dSmgV5ueL0XVIEZU/MZKcRMFM8urAMCKl0r3jccZMF9DsTqZTSNT+GOzuXIpCALMH/nL3QMUUgq25L6KcVdDNSqnvWrN7WC/AcuZtm9c5OtQsiNHo52ljfkCIYq8iuTN1RBOlo7wIULjPojhEA12i5lquuBIkiUGUVJGuNR962AmC5BkT0AQEKTvQgQHHXZjDVFU+AhcN0w52E6agoArmc1grFtPPc2QjMbGNgSz8QjBcLPQhQOEGi7r6tprNgtSOKQJAkBf53sociMDyjgvpREKHRE10PUEAlVu4u3V0ZgJc27UiMyKsOEcSN7gcoBkwt5hf0t2lGEKSxFXY5QDFgosuAMG+7QNVwIJlMrdpX7x4xRtom+KrmIZcBwQiScnEsWqx1OUAxYBrYAEUvK6WDpUH3Ba7r7Nb3HVMEZiUP+ErKmf09EAiYN72GeN9xm7c7Dub7ju1BLLqsmpKslWnhMxAI2r/plb02s/9cWcFIKY7eWZa0i//BQOC98C73BUq0JoJC4zu/RLBzsoPVpixVyo0OrAFAIOAXqYyXQLxQ2c0IlIqKlw3nDA3wluXkRv8RlFQnQKHv6BoUO61ivCwNZqWUIEjJKZCXc7sZgYa6xrvYNPMh2HLTjFoBepHKLg9QZPEICrb+LKJvL0XYweNW1JsQDZHAXCNqjjApXGCAQkhHYUU0WSiW9WK5sJutoJV0lZXQeUIIBfYcluNFLUJepILnMb+YCPoqQS75KqWve1dofL3LL1J5KUa5JPum11f/k5HFBnjNNvti4BSPl2ouwe2H+n0zL7Xb9P/WNH/cjIII7AAAAABJRU5ErkJggg==\"  width=\"350\" ></center>\n",
    "<center> Figure 2: Example of matching compatibility matrix $W$ and edge similarity matrix $S$. Source: Cour et al. (2005). </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zZTiALEjdTU9"
   },
   "source": [
    "## Benchmark algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sX-uvuQDqfvE"
   },
   "source": [
    "### SDP relaxation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBmg1z2bAa3s"
   },
   "source": [
    "SDP relaxation applied to graph matching is proposed by Schellewald et al. in \"Probabilistic subgraph matching based on convex relaxation\" (2005). The goal here is to make the objective  and the constraints convex through the introduction of semi-definite positive matrices. Namely, the first step of SDP relaxation is to rewrite the objective as an matrix inner product: \n",
    "$$x^\\top W x = \\langle X, W_{eq} \\rangle_F = \\text{Tr}(W_{eq}^\\top X)$$ where\n",
    "X = $$\n",
    "\\left( \\begin{array}{cc}\n",
    "1  \\\\\n",
    "x \n",
    "\\end{array} \\right)\n",
    "%\n",
    "\\left( \\begin{array}{cc}\n",
    "1 & x^\\top \\\\\n",
    "\\end{array} \\right)\n",
    "= \\left( \\begin{array}{cc}\n",
    "1 & x^\\top \\\\\n",
    "x & xx^\\top\n",
    "\\end{array} \\right)$$ and  $$W_{eq} = \\left( \\begin{array}{cc}\n",
    "0 & d^\\top /2 \\\\\n",
    "d/2 & W-D \n",
    "\\end{array} \\right) = W_{eq}^\\top$$ where $d=\\text{diag}(W)$ and $D$ is a diagonal matrix with diagonal $d$. The following formulation can be rapidly check as: \n",
    "$$ \\text{Tr}(W_{eq}^\\top X) = \\text{Tr}(W_{eq} X) = \\text{Tr}\\left( \\begin{array}{cc}\n",
    "d^\\top x/2& d^\\top xx^\\top /2  \\\\\n",
    "d/2 + (W-D)x & dx^\\top /2 + (W-D)xx^\\top\n",
    "\\end{array} \\right)$$ The previous expression is then equal to:\n",
    "$$\\text{Tr}(dx^\\top) + \\text{Tr}(x^\\top W x) - \\text{Tr}(x^\\top D x)$ = x^\\top W x - \\displaystyle \\sum_i^{nn'} d_i(x_i-x_i^2)$$ using commutativity of the trace. At last, one may remark that $x$ being an integer vector, $x_i^2=x_i \\, \\forall \\, i$ so it shows that the SDP relaxation is valid. \n",
    "Now, besides being symmetric, the matrix $X$ is positive semidefinite with rank $1$. SDP relaxation relax the rank $1$ non-convex condition in order to only require that $X$ is positive semi-definite. Thus, program $(4)$ now becomes:\n",
    "\\begin{equation}\n",
    "\\tag{SDP}\n",
    "    \\max_{X} \\text{Tr}(W_{eq} X) \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} X \\succeq 0 \\hspace{0.5cm} \\text{and} \\hspace{0.5cm} (\\star)\n",
    "\\end{equation} where now the set of $X$ is the set of psd matrices which is convex (it can be shown using the basic property of convexity). Nevertheless, we still need to treat the constraints $(\\star)$ and incorporate the latter into the SDP relaxation by specifying appropriate constraint matrices. We wish thos SDP constraints to have the form:\n",
    "$$\\text{Tr}(C_{eq}^{(i)} X) \\leq b_{eq}^{(i)} $$ for suitable $C_{eq}^{(i)} $ and $b_{eq}^{(i)}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hIltLXQgMk76"
   },
   "source": [
    "*   First, we have to deal with the first constraint that results from the homogeneization of the problem, namely, the first element of $X$ equal $1$ : $X_{11}=1$. This can be expressed as:\n",
    "$$C_{eq, kl}^{(1)} = \\delta_{k1}\\delta_{l1} \\hspace{0.5cm} \\text{for} \\hspace{0.5cm}  k, l = 1,..., nn'+1$$ and $$b_{eq}^{(1)} = 1$$\n",
    "\n",
    "\n",
    "*   The second constraint is derived from the integer constraints $x_i \\in \\{0,1\\}, i=1,..., nn'+1$, which can be rewritten as $x_i^2=x_i$. Therefore, the elements on the diagonal of $X$ are equal to the ones in the first column and row of $X$ (this can be easily seen by just writting $X$). The consequence of this observation is that the 0/1 integer constraint can be enforced in the relaxed problem by requiring the first column and row of $X$ to be equal to its diagonal. To do so, one may follow closely the article from Schellewald (2005). The authors propose to introduce $nn'$ constraint matrices $C_{eq}^{(j)}$ for $j=2,...,nn'+1$ whose elements verify:\n",
    "$$C_{eq, kl}^{(j)} = 2 \\delta_{kj} \\delta_{lj} - \\delta_{kj} \\delta_{l1} - \\delta_{lj} \\delta_{k1} \\hspace{0.5cm} \\text{for} \\hspace{0.5cm} k,l=1,...,nn'+1$$\n",
    "These matrices have thus a $2$ at the corresponding $j$-th diagonal and $-1$ at the corresponding elements in the first column and the first row. And zeros everywhere else. Then, $\\text{Tr}(C_{eq}^{(j)} X) = 2(x_j^2-x_j)$ which, to fit the 0/1 integer constraints, has to be equal to $0$. Hence, \n",
    "$$b_{eq}^{(j)} =0$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TN3eDZNQTjrw"
   },
   "source": [
    "* The third constraint to take into account comes from the mapping constraints. Namely, we should have that $\\displaystyle \\sum_{i=1}^n x_{i'i}=1$ for all $i'=1,...,n'$. To recall, these constraint represent the fact that each node of the bigger graph (here we take $G'$) is mapped to exactly one node of $G$, the smaller graph here. We need once again to exploit the fact that $x_i=x_i^2$. Indeed, our previous condition can be written as $\\displaystyle \\sum_{i=1}^n x_{ii'}^2=1$ for all $i'=1,...,n'$. Thus, the intuition is that, for a given $i'$, we should multiply the diagonal elements $x_{ii'}^2$ from matrix $X$ by one and then force the sum to be equal to $1$. More formally, if we set $C_{eq}^{(j)}$ for $j=1,...,n'$ such that:\n",
    "$$C_{eq, kl}^{(j)} = \\displaystyle \\sum_{i=(j-1)n+1}^{jn+1} \\delta_{ik} \\delta_{il} \\hspace{0.5cm} \\text{for} \\hspace{0.5cm} k,l=1,...,nn'+1$$ and $$b_{eq}^{(j)}=1$$ Then $\\text{Tr}(C_{eq}^{(j)}X)=b_{eq}^{(j)}$ is equivalent to the original condition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ji44IT4Q-_dR"
   },
   "source": [
    "* The fourth constraint is relative to the one-to-many constraints. Namely, we should also have that $\\displaystyle \\sum_{i'=1}^{n'} x_{ii'} \\geq 1$ for all $i=1,...,n$. It means that one vertex of the smaller graph (say $G$) can map at least one vertex of $G'$. The reasoning is quite similar to the previous one, except that now we will require the diagonal elements separated by $n'$ elements to sum to $1$. More formally, if we set $C_{eq}^{(j)}$ for $j=1,...,n$ such that:\n",
    "$$C_{eq, kl}^{(j)} = \\displaystyle \\sum_{i=1}^{n'+1} \\delta_{(i-1)n'+j,k} \\delta_{(i-1)n'+j,l} \\hspace{0.5cm} \\text{for} \\hspace{0.5cm} k,l=1,...,nn'+1$$ and $$b_{eq}^{(j)}=1$$ Then $\\text{Tr}(C_{eq}^{(j)}X) \\geq b_{eq}^{(j)}$ is equivalent to the original condition. \n",
    "\n",
    "* The last condition, $\\displaystyle \\sum_{i'=1}^{n'} x_{ii'} \\leq K$ for all $i=1,...,n$ uses the negation of the same constraint matrices as above such that: \n",
    "$C_{eq}^{(j)}$ for $j=1,...,n$ such that:\n",
    "$$C_{eq, kl}^{(j)} = - \\displaystyle \\sum_{i=1}^{n'+1} \\delta_{(i-1)n'+j,k} \\delta_{(i-1)n'+j,l} \\hspace{0.5cm} \\text{for} \\hspace{0.5cm} k,l=1,...,nn'+1$$ and $$b_{eq}^{(j)}=-K$$ Then $\\text{Tr}(C_{eq}^{(j)}X) = - \\text{Tr}(-C_{eq}^{(j)}X) \\geq b_{eq}^{(j)}=-K$ is equivalent to the original condition by multiplying this inequality by $-1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WW057dTRHEaa"
   },
   "source": [
    "As a conclusion, the SDP relaxation introduces $1+nn'+n'+2n=(1+n)(1+n')+n:=k$ convex constraints in addition to $X \\succeq 0$. Finally, the relaxed program becomes:\n",
    "\\begin{equation}\n",
    "\\tag{SDP}\n",
    "    \\max_{X} \\text{Tr}(W_{eq} X) \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} X \\succeq 0 \\hspace{0.5cm} \\text{and} \\hspace{0.5cm}\\text{Tr}(C_{eq}^{(i)} X) \\leq b_{eq}^{(i)} \\, \\, \\text{for} \\, \\, i=1,...,k\n",
    "\\end{equation} and $k$ the number of constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbWrlUcWZrRi"
   },
   "source": [
    "### Gradiated Assignment (GA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7eIwsBgLEH6"
   },
   "source": [
    "The graduated assignment technique for one-to-many graph matching problems has been originally proposed by Gold et al. in \"A graduated assignment algorithm for graph matching\" (1996). Here, the term assignment refers to a correspondence between one set of objects and another. Precisely, an element from matrix $M$ (or vector $x$) is equal to $1$if one set is assigned to (or corresponds to) a given object in the other set. This algorithm will be particularly useful for our implementation and may require a specific attention. Gold et al. (1996) problem formulation is part of *weigthed graph matching* problems. Problem $(4)$ remains unchanged as for the mapping constraints. \n",
    "\n",
    "The authors first recall that the main difficulty of graph matching problem is to satisfy the two-way (or more for one-to-many matching) mapping constraints. First, they ignore the inequality constraints so that the constraint is equivalent to $M$ being a permutation matrix. Indeed, we restrict ourselves to one-to-one matching. This implies that  A permutation matrix is such that it is binary and whose rows and columns add up to one. In other words, we first ignore the slack variables which aim at shifting the inequality constraints to equality constraints. Namely, ... \n",
    "\n",
    "\n",
    "<center><img src=\"https://csdl-images.computer.org/trans/tp/1996/04/figures/i03772.gif\"  width=\"150\" ></center>\n",
    "<center> Figure 3: matrix $M$ with slack variables, equivalent to $x$ being reshape into matrix of size $n\\times n'$. Source: Gold et al. (1996)</center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9QsrHqqTxUI"
   },
   "source": [
    "We provide below a simple implementation of Graduated Assignment for one to one matching. As we only have equality constraints we do not need to add slack variables here.\n",
    "\n",
    "Note that we do not take advantage of the sparsity here using matrix products instead of computing the gradient and the objective only with the non-zeros values. We choose this formulation for the sake of simplicity as we will only test our function on basic examples where the code is still fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSgj50LkUb42"
   },
   "outputs": [],
   "source": [
    "def GA_matrix(W, n, x0, b0=0.5, bf=10., br=1.075,\n",
    "              tol0=0.5, tol1=0.05, itermax0=30, itermax1=30, display_step=False):\n",
    "    \"\"\"\n",
    "    :param W: Compatibility matrix\n",
    "    :param n: size the graphs\n",
    "    :param x0: starting assignment\n",
    "    :param b0: starting control parameter\n",
    "    :param bf: upper value of the control parameter\n",
    "    :param br: increase rate for the control parameter\n",
    "    :param tol0: tolerance for convergence of the gradient descent on bistochastic x\n",
    "    :param tol1: tolerance for bistochastic normalization of x\n",
    "    :param itermax0: maximal number of iterations for the gradient descent on bistochastic x\n",
    "    :param itermax1: maximal number of iterations for a single normalization\n",
    "    :param display_step: show x for each control parameter\n",
    "    :return: bistochastic approximation of the solution of 1 to 1 matching\n",
    "    \"\"\"\n",
    "    beta, x = b0, x0\n",
    "    while beta < bf:\n",
    "        err, n_iter = np.inf, 0\n",
    "        while err > tol0 and n_iter < itermax0:\n",
    "            prev_x = copy(x)\n",
    "            Q = np.dot(W, x)\n",
    "            x = np.exp(beta*Q)\n",
    "            err1, n_iter1 = np.inf, 0\n",
    "            x = x.reshape((n, n))\n",
    "            while n_iter1 < itermax1 and err1 > tol1:\n",
    "                prev_x1 = copy(x)\n",
    "                x = np.apply_along_axis(lambda y: y/y.sum(), 0, x)\n",
    "                x = np.apply_along_axis(lambda y: y/y.sum(), 1, x)\n",
    "                err1 = np.sum(np.abs(x-prev_x1)**2)\n",
    "                n_iter1 += 1\n",
    "            x = x.flatten()\n",
    "            x = np.round(x, 6)\n",
    "            err = np.sum(np.abs(x-prev_x)**2)\n",
    "            n_iter += 1\n",
    "        beta *= br\n",
    "        if display_step:\n",
    "            print('beta {}'.format(beta))\n",
    "            print(x.reshape((n, n)))\n",
    "    return np.round(x, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUxndNBbZrj0"
   },
   "source": [
    "### Spectral Matching (SM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cgLnVZ3ZrbP"
   },
   "source": [
    "This last relaxation method is based on the work of Leordeanu et al., \"A Spectral Technique for Correspondence Problems Using Pairwise Constraints\" (2005). It has the particularity to relax the mapping constraints and the integral constraints on $x$, such that the optimization problem becomes:\n",
    "\\begin{equation}\n",
    "\\tag{SM}\n",
    "R(x) = x^\\top W x \\hspace{1cm} \\text{s.t.} \\hspace{1cm} \\|x\\|^2 = 1\n",
    "\\end{equation}\n",
    "We see that $R(x) = R(cx)$ with $c$ a scalar. Thus, $R$, called the Rayleigh quotient, is invariant by translation, which allows to just study the special case $\\|x\\|^2=x^\\top x = 1$. Writing the Lagrangian of the program above leads to solving $Wx=\\lambda x$ with $\\lambda$ the Lagrange multiplier. Thus, the critical points of the Rayleigh quotient are the eigenvectors of $W$ with their corresponding eigenvalues. Thus, there could be multiple stationary points for the solution to exist. However, $W$ being non-negative elementwise, we can make use of the Perron-Frobenius theorem. First, let's recall that the elements of $W$, $W_{ii',jj'}=f(A_{ij},A_{i'j'}')$ are taken non-negative in both articles. In Cour et al. experiments, $W_{ii',jj'}=\\exp(-|A_{ij}-A_{i'j'}'|^2) > 0$ $\\forall \\, ij \\in E, i'j' \\in E'$. This allows to apply Perron-Frobenius theorem which has important applications to graph theory. This theorem applies to positive matrices but generalizes to non-negative ones, which is correct here. It states that if $W$ has non-negative entries, then it has a nonnegative real eigenvalue $\\lambda$ which has maximum absolute value among all eigenvalues. This eigenvalue $\\lambda$ has a nonnegative real eigenvector. If we rewrite $R$ evaluated to one of its critical points $x^*$, then $R(x^*)=x^{*^\\top}Wx^* = x^{*^\\top} \\lambda^ *x^* = \\lambda$. From Perron-Frobenius theorem, we know that their exist a unique eigenvalue of $W$, nonnegative, which dominates the other and whom corresponding eigenvector is nonnegative too. Thus, program (SM) can be solved by computing the leading eigenvector, or Perron eigenvector of $W$. As $x^*$ is nonnegative and $\\|x^*\\|^2=1$, then the elements of $x^*$ necessarily lie in the interval $[0,1]$. Leordeanu et al. (2005) argue that their spectral matching method benefits from an important computational gain. The latter coming from the removal of both the mapping constraints and the integral constraints during the optimization step. Those constraints are then incorporated only afterwards during the binarization of the eigenvector. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1ke4V_8Ux0r"
   },
   "source": [
    "The spectral Matching algorithm is pretty straightforward to implement. Note that the numpy eigensolver can be quite unstable in some situations. In our results we could check that this is not necessarily a problem: the leading eigenvector estimation seem quite accurate in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQFBpBcnUq6z"
   },
   "outputs": [],
   "source": [
    "def SM(W):\n",
    "    \"\"\"\n",
    "    :param W: affinity matrix\n",
    "    :return: leading eigenvector of W if W is non-negative\n",
    "    \"\"\"\n",
    "    l, v = eigh(W)\n",
    "    v = np.round(v, 6)\n",
    "    s = v.sum(axis=0)\n",
    "    for i in range(v.shape[1]):  #remove spurious results\n",
    "        if s[i] == 0:\n",
    "            l[i] = 0\n",
    "    lead_ind = np.argmax(l)\n",
    "    lead_ev = v[:, lead_ind]\n",
    "    return np.abs(lead_ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chvI_9Sqqfz8"
   },
   "source": [
    "## Spectral Matching with Affine Constraint (SMAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtEHafd8qf6W"
   },
   "source": [
    "As we said, the first contribution of the authors is to propose a new algorithm, *Spectral Matching with Affine Constraint*. This algorithm is inspired from spectral matching but allows to impose affine constraints $Cx=b$ on the relaxed solution before the discretization step instead of dropping it. Thus, SMAC benefits from the scalability and speed of SM and may provide more effective solution to the graph matching problem through the ability to maintain this constraint. SMAC algorithm solve the following optimization program:\n",
    "\\begin{equation}\n",
    "\\tag{5}\n",
    "    \\max_x \\frac{x^{\\top}Wx}{x^{\\top}x} \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} Cx=b\n",
    "\\end{equation}\n",
    "where $Cx=b$ will be made explicit just after. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWzjPdfvrKuL"
   },
   "source": [
    "### Computational solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xN924OIhrKzD"
   },
   "source": [
    "\n",
    "The authors define problem (5) as a *Rayleigh Quotient under Affine Constraint* , i.e. a generalization of Rayleigh Quotient:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tag{6}\n",
    "    \\max_x \\epsilon_1(x) = \\frac{x^{\\top}Ax}{x^{\\top}Bx} \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} Cx=b\n",
    "\\end{equation} with $x \\in \\mathbb{R}^p, b\\in \\mathbb{R}^k, B \\succ 0, C \\in \\mathbb{R}^{k\\times p}$ of full rank with $k<n$. This part aims at detailing the computation of the solution.\n",
    "\n",
    "The first step is to transform the affine constraint into a linear constraint $C_{eq}x=0$. We take the particular case $B=I$ in order to fit to our problem (for the general case, we should consider $y=B^{-1/2}x$ to get rid of matrix $B$). Problem $(6)$ is equivalent to:\n",
    "\\begin{equation}\n",
    "\\tag{7}\n",
    "    \\max_{z, t} \\epsilon_2(z, t) = \\frac{z^{\\top}Az}{z^{\\top}z} \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} Cz=tb\n",
    "\\end{equation} where $t \\in \\mathbb{R}$. Indeed, $(z^*, t^*)$ is an optimum of $(7)$ if and only if $x^* = (1/t^*)z^*$ is an optimum of $(6)$. In the case where $t^*=0$, problem $(6)$ has no solution whereas $(7)$ has one. From now on, we suppose that $t^* \\neq 0$. Then, the authors describe three different methods to solve $(7)$. We consider the third one, which is the most computationally efficient (and the one chosen in the article).\n",
    "\n",
    "\n",
    "Let $b_k$ be the last coefficient of vector $b$ and $k$ the number of constraints. We assume without loss of generality that $b_k \\neq 0$ (otherwise we can reorder the rows of $C$ and $b$). The key basis of the method lies in the following equivalence:\n",
    "\n",
    "\n",
    "$$\\Big[\\exists t \\, : \\, Cz = tb \\Big] \\Longleftrightarrow \\Big[ \\forall i \\, \\in \\, [1, k-1], (Cz)_i = (1/b_k)(Cz)_kb_i \\Big]$$\n",
    "\n",
    "Indeed, $t=(Cz)_i / b_i = (Cz)_k / b_k \\, \\, \\forall \\, i \\, \\in \\, [1, k-1]$. Then, for all $i \\, \\in \\, [1, k-1]$,  \n",
    "\\begin{eqnarray}\n",
    "& \\displaystyle \\sum_{\\ell} C_{i\\ell}z_\\ell - \\frac{1}{b_k} \\displaystyle \\sum_\\ell C_{k\\ell}z_\\ell b_i & =  0 \\\\\n",
    "\\Longleftrightarrow & \\displaystyle \\sum_{\\ell} \\Bigg( C_{i\\ell}z_\\ell - \\frac{1}{b_k} C_{k\\ell} b_i \\Bigg) z_\\ell &= 0 \\\\\n",
    "\\tag{8}\n",
    "\\Longleftrightarrow & \\Big(C_i - \\frac{1}{b_k} C_k b_i\\Big) z &= 0 \n",
    "\\end{eqnarray}\n",
    "Now, if we set $J=[I_{k-1} \\,; 0] \\in \\mathcal{M}^{k-1 \\times k}$ (i.e. the canonical projector $\\mathbb{R}^k \\rightarrow \\mathbb{R}^{k-1}$), the previous equation is equivalent to:\n",
    "\\begin{equation}\n",
    "    J(C-(1/b_k)bC_k)z = C_{eq}z=0\n",
    "\\end{equation} where $C_k$ is the last row of $C$. Indeed, the sub-product $I_{k-1} \\cdot \\Big(C-(1/b_k)bC_k\\Big)$ represents the previous conditions $(8)$. $C_{eq}$ now defines the new linear constraint matrix. \n",
    "\n",
    "___\n",
    "Therefore, problem $(5)$ can be rewritten as:\n",
    "\\begin{equation}\n",
    "\\tag{9}\n",
    "    \\max_x x^{\\top}Wx \\hspace{0.5cm} \\text{s.t.} \\hspace{0.5cm} C_{eq}x=0, \\hspace{0.5cm} x^{\\top}x = ||x||^2 = 1\n",
    "\\end{equation}\n",
    "due to the invariance by translation of the Rayleigh Quotient.\n",
    "___\n",
    "\n",
    "The Lagrangian associated with $(9)$ is as follows: $$\\mathcal{L}(x; \\lambda, \\mu) = x^{\\top}Wx + \\lambda(1-||x||^2) + \\mu^{\\top}(-C_{eq}x)$$ Hence, \n",
    "\n",
    "\n",
    "\\begin{array}{cccl}\n",
    "     & \\nabla_x \\mathcal{L}(x; \\lambda, \\mu) &=& 2Wx - 2\\lambda x - \\mu^{\\top}C_{eq} = 0 \\\\\n",
    "     \\Longleftrightarrow &  2Wx &=& 2\\lambda x + C_{eq}^{\\top} \\mu \\\\\n",
    "     \\Longleftrightarrow &  2C_{eq}Wx &=& 2\\lambda C_{eq} x + C_{eq}C_{eq}^{\\top} \\mu \\\\\n",
    "     \\Longleftrightarrow &  \\mu &=& \\big( C_{eq}C_{eq}^{\\top} \\big)^{-1} \\big( 2C_{eq}Wx - 2\\lambda  C_{eq} x \\big) \\\\\n",
    "     \\Longrightarrow & 2Wx &=& 2\\lambda x + 2C_{eq}^{\\top} \\big(C_{eq}C_{eq}^{\\top} \\big)^{-1} C_{eq}\\Big(Wx -\\lambda x \\Big) \\\\\n",
    "     \\Longleftrightarrow & Wx - C_{eq}^{\\top} \\big(C_{eq}C_{eq}^{\\top} \\big)^{-1} C_{eq}Wx &=& \\lambda x - C_{eq}^{\\top} \\big(C_{eq}C_{eq}^{\\top} \\big)^{-1} C_{eq} \\lambda x \\\\\n",
    "     \\Longleftrightarrow & (I-C_{eq}^{\\top} \\big(C_{eq}C_{eq}^{\\top} \\big)^{-1} C_{eq})Wx &=& \\lambda (I-C_{eq}^{\\top} \\big(C_{eq}C_{eq}^{\\top} \\big)^{-1} C_{eq})x \\\\\n",
    "     \\Longleftrightarrow & P_C W x &:=& \\lambda P_C x\n",
    "\\end{array}\n",
    "\n",
    "From these derivations yield the final result that the solution of $(5)$ is  given by the leading eigenpair of \n",
    "\\begin{equation}\n",
    "    P_CWP_Cx = \\lambda x \n",
    "\\end{equation} as $P_Cx=x$ since $x$ verifies the linear constraint $C_{eq}x=0$. Here again, we use Perron-Frobenius theorem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tEchxxjHWErJ"
   },
   "source": [
    "The implementation of the SMAC basically consists in computing the matrix $P_c$ and reusing our implementation of the Spectral Matching algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jWCYhHPWSnN"
   },
   "outputs": [],
   "source": [
    "def get_Pc_SMAC(C, b):\n",
    "    \"\"\"\n",
    "    :param C: Constraints matrix\n",
    "    :param b: value of each constrain\n",
    "    :return: Modified matrix Pc, as defined in Cour et al \n",
    "    \"\"\"\n",
    "    k = C.shape[0]\n",
    "    Ik = np.zeros((k-1, k))\n",
    "    Ik[:, :-1] = np.eye(k-1)\n",
    "    for i in range(k):\n",
    "        C[i] = C[i] - b[i]/b[-1]*C[-1]\n",
    "    Ceq = np.dot(Ik, C)\n",
    "    inv_C = np.linalg.inv(np.dot(Ceq, Ceq.T))\n",
    "    all_C = np.dot(Ceq.T, np.dot(inv_C, Ceq))\n",
    "    return np.eye(C.shape[1])-all_C\n",
    "  \n",
    "  \n",
    "def SMAC(W, Pc):\n",
    "    \"\"\"\n",
    "    :param W: Compatibility Matrix\n",
    "    :param Pc: Matrix obtained by transforming the constraint matrix, according to the paper\n",
    "    :return: leading eigenvector of Pc*W*Pc\n",
    "    \"\"\"\n",
    "    new_W = np.dot(Pc, np.dot(W, Pc))\n",
    "    return SM(new_W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LhUFZ9fqf3a"
   },
   "source": [
    "### Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Ck1gulGrsp0"
   },
   "source": [
    "SMAC is based on a continuous relaxation of the IQP. As such, a post-processing step is needed to discretize the continuous solution while satisfying the desired constraints. If we reshape the solution $x$ into a $n\\times n'$ matrix, then the constraints in $(4)$ can be rewritten as :\n",
    "\\begin{equation}\n",
    "    X \\mathbf{1_{n'}} = \\mathbf{1_{n'}}, \\hspace{1cm} X^{\\top} \\mathbf{1_n} = \\mathbf{1_{n}}, \\hspace{1cm} X \\in \\mathcal{O}(n,n'), \\hspace{1cm} X \\geq 0 \\, \\text{ elementwise}\n",
    "\\end{equation} where $\\mathbf{1_n}$ and $\\mathbf{1_{n'}}$ correspond to the constant $n$ and $n'$ dimensional vectors of all ones respectively. Let's assume now that $n=n'$. Then, one can remark that the previous constraints can be summarised by \\textbf{\"$X$ belongs to the set of permutation matrices\"} whose convex hull is the set of bistochastic matrices, where the the constraint $X \\in \\{0,1\\}^{n\\times n}$ is replaced by $X \\in [0,1]^{n\\times n}$. The authors propose to incorporate the first $3$ constraints (out of $4$)  as a post-processing step before the final discretisation. Let's focus on it through the general case where $n \\neq n'$. \\newline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htCDS-QBr97s"
   },
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1Y8S0sjr-WQ"
   },
   "source": [
    "The first step is to reshape the continuous solution $x$ into a $n\\times n'$ matrix $X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cP6Kq9tsFP7"
   },
   "source": [
    "### Orthogonal approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQ3vxcEEr-Qm"
   },
   "source": [
    "Then, one should compute the best orthogonal approximation $X_{orth}$ of $X$: \n",
    "\n",
    " \\begin{eqnarray}\n",
    "    X_{orth} &=& \\operatorname{argmin}_Q\\{\\|X-Q\\|_F : Q \\in O(n,n')\\}\n",
    " \\end{eqnarray}\n",
    " \n",
    " This can be done using the Singular Value Decomposition (SVD) of $X$, namely $X=U\\Sigma V^{\\top}$ where $U$ and $V$ are $2$ orthogonal matrices, $U \\in O(n), V \\in O(n'), \\Sigma \\in \\mathbb{R}^{n \\times n'}$. If we denote $p$ as $p=\\min(n,n')$, then $\\Sigma = \\text{diag}(\\sigma_1,...,\\sigma_p, 0, ..., 0)$ where $\\sigma_1,...,\\sigma_p$ are the singular values of $Q$ and are positive. We should show now the following key result from Procrustes theory applied to the strategy of discretization:\n",
    "\\begin{eqnarray}\n",
    " X_{orth} = UV^\\top\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\\hspace{-0.7cm} First, let's notice that \n",
    " $$X_{orth} = \\operatorname{argmin}_Q\\{\\|X-Q\\|_F : Q \\in O(n,n')\\} = \\operatorname{argmin}_Q\\{\\|X-Q\\|^2_F : Q \\in O(n,n')\\}$$\n",
    " Using the distributivity of the inner product (w.r.t to the Frobenius norm):\n",
    "\\begin{equation}\n",
    "\\begin{array}{ccl}\n",
    "    \\|X-Q\\|^2_F &=& \\langle X-Q,X-Q \\rangle_F\\\\\n",
    "    & = & \\|X\\|^2_F + \\|Q\\|^2_F - 2 \\langle X, Q \\rangle_F\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "With $$ \\|Q\\|^2_F = \\text{Tr}(Q^{\\top} Q) = \\text{Tr}(I_{n'\\times n'}) = n'$$ As the sum $\\|X\\|^2_F + n'$ does not depend on $Q$, the optimization problem can be simplified as follows:\n",
    "\\begin{equation}\n",
    "\\begin{array}{ccl}\n",
    "    Q^* = \\operatorname*{argmax}\\limits_{Q \\in O(n, n')} \\langle X, Q \\rangle_F\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "Now we can introduce the Singular-Value Decomposition of $X=U\\Sigma V^T$. \n",
    "\\begin{equation}\n",
    "\\begin{array}{ccl}\n",
    "    Q^* = \\operatorname*{argmax}\\limits_{Q \\in O(n, n')} \\langle Q, X \\rangle_F = \\operatorname*{argmax}\\limits_{Q \\in O(n, n')} \\langle Q, U\\Sigma V^T \\rangle_F\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "where $U \\in O(n), V \\in O(n'), \\Sigma \\in \\mathbb{R}^{n \\times n'}$. If we denote $p$ as $p=\\min(n,n')$, then $\\Sigma = \\text{diag}(\\sigma_1,...,\\sigma_p, 0, ..., 0)$ where $\\sigma_1,...,\\sigma_p$ are the singular values of $Q$. Now, using basic properties of the trace we have that:\n",
    "\\begin{equation*}\n",
    "\\begin{array}{ccl}\n",
    "    \\langle Q, U\\Sigma V^T \\rangle_F &=& \\mbox{Tr}([Q^{\\top}U][\\Sigma V^{\\top}]) \\\\\n",
    "    &=& \\mbox{Tr}([\\Sigma][V^{\\top} Q^{\\top} U]) \\\\\n",
    "    &=& \\mbox{Tr}(V^{\\top} Q^{\\top}U\\Sigma) \\\\\n",
    "    &=& \\mbox{Tr}((U^{\\top}QV)^{\\top}\\Sigma) \\\\\n",
    "    &:=& \\mbox{Tr}(Z^{\\top}\\Sigma) \\\\\n",
    "    &=& \\displaystyle \\sum_{i=1}^p Z_{ii} \\sigma_i \n",
    "\\end{array}\n",
    "\\end{equation*}\n",
    "As $Z:=U^{\\top}QV$ is a product of orthogonal matrix, it is still an $(n, n')$-dimensional rectangular orthogonal matrix whose rows' coefficients (or columns' coefficients) sum to 1 if $n \\leq n'$ (or $n' \\leq n$, due to linear dependence). So in any case $Z_{ii}\\leq1 \\, \\forall \\, i \\in \\{1,...,p\\}$. As maximizing in $Q$ is equivalent to maximizing in $Z$ (as $Z$ is a linear transformation of $Q$), we have that our final expression is maximal if and only if $Z_{ii}=1\\, \\forall \\, i=1,...,p$, that is to say $Z^{*}= U^{\\top}Q^*V= [I_{p\\times p}, 0]$ (if $n \\leq n'$, otherwise $[I_{p\\times p}, 0]^T)$. Which prooves that $Q^* = UV^{\\top}$. \\color{red} Conclusion à finir \\color{black}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMiUIYfzr-LY"
   },
   "source": [
    "### Affine constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZeU_C1wr-G2"
   },
   "source": [
    "\\hspace{-0.7cm} Let's suppose that $u$ is left and right eigenvector of $X$. Hence, $u$ is an eigenvector of $X$ and $X^\\top$. Simple calculation allows to show that $u$ is then an eigenvector of both $XX^\\top$ and $X^\\top X$. By construction of the Singular Value Decomposition, the columns of $U$ are the eigenvectors of $XX^\\top$ and the columns of $V$ are the eigenvectors of $X^\\top X$. Then, $u$ is a column in $U$ and in $V$. Namely, $u$ is a left and right singular vector of $X$. Therefore, all other singular vectors in $U$ and $V$ are orthogonal to $u$. It yields $UV^\\top u = \\|u\\|^2 \\cdot u$ and so $X_{orth} u = \\|u\\|^2 \\cdot u$ as $X_{orth}$ is orthogonal. Reversely, we can show that $X_{orth} u = \\|u\\|^2 \\cdot u$. Hence, $u$ is left and right eigenvector of $X_orth$. Since $X_{orth}$ is orthogonal, $\\|u\\|^2=1$. Now, as $X$ verifies the $4$ constraints,  $\\mathbf{1}_n$ is a left and right eigenvector of $X$, and hence of $X_{orth}$. Finally, $X_{orth} \\mathbf{1}_n = \\mathbf{1}_n$ and $X_{orth}^\\top \\mathbf{1}_n = \\mathbf{1}_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cB-VNsVYbHjM"
   },
   "source": [
    "## Discretization step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "194CT4Z7bLzd"
   },
   "source": [
    "As the algorithms we studied use continuous relaxation to propose a solution of our Integer Quadratic Problem, a supplementary step is necessary to convert this solution into an acceptable one. This means that we need to reintroduce the constraints and to provide a binary output.\n",
    "\n",
    "Now let's consider that our output is a $n\\times n'$ matrix (by reshaping it). For one to one matching, these constraints just imply that our output $n \\times n$ output must be a permutation matrix. This step can be handled with a simple 2 step procedure:\n",
    "\n",
    "* Run Graduated Assignment using the output of the first algorithm as the starter. If the algorithm is successful then the output should be transformed into a bistochastic matrix. This is very interesting a each row/column of the matrix can be interpreted as a marginal probability of one vertice of the first/second graph with the vertices of the other graphs.\n",
    "\n",
    "* If the output of GA is not a permutation matrix, run a new procedure based on a probability interpretation of the coefficients of the matrix. This procedure can either be greedy or randomized. We implemented different procedure introduced in  the paper cited by Cour et al.\n",
    "\n",
    "For this second step, a naive approach is a greedy selection of the coefficients that will be set to one: if a coefficient $x_{ij}$ is both the maximum of its row and column, then the matching $(i,  j)$ is the most probable for both vertices and hence it is reasonable to integrate it in our final solution.\n",
    "Unfortunately, this approach is often not sufficient to provide all assignments and it need to be completed with other tests. To this extent, we implemented a randomized procedure for the left vertices based on a simple sampling algorithm:\n",
    "* Draw uniformly at random one of the left vertices $i$ of the first graph\n",
    "* Extract the raw $x_i$, set the value of the already assigned elements $j$ of the second graph to zero and normalize the raw to get a probability vector $p_i$ of size $n$.\n",
    "* Draw a vertice $j$ with probability $p_i(j)$ and set $x_{ij}=1$ and $x_{i'j}=x_{ij'}=0$ for all others $i', j'$.\n",
    "* Restart the procedure while $x$ is not a permutation matrix\n",
    "\n",
    "We tested this procedure, which seems to provide good results. Our implementation is below. Actually, Cour et al. used another greedy procedure in their experiments QUE JE DETAILLERAI ET IMPLEMENTERAI SI J'AI LE TEMPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_one_to_one(W, n, x_res, is_GA=False, n_sampling = 100):\n",
    "    \"\"\"\n",
    "    :param W: Affinity matrix\n",
    "    :param x: Result from the first algorithm\n",
    "    :param is_GA: True if the first algorithm is Graduated Assignment\n",
    "    :return: Discretized solution for one to one matching (i.e a Permutation Matrix)\n",
    "    \"\"\"\n",
    "    if not is_GA:\n",
    "        x = GA_matrix(W, n, x0=x_res)\n",
    "    else:\n",
    "        x = copy(x_res)\n",
    "\n",
    "    # Check if the solution is already a permutation matrix\n",
    "    row_sum = np.dot(x.reshape((n, n)), np.ones(n))\n",
    "    col_sum = np.dot(x.reshape((n, n)).T, np.ones(n))\n",
    "    diff_row, diff_col = row_sum - np.ones(n), col_sum - np.ones(n)\n",
    "    if np.abs(diff_row).sum() == 0 and np.abs(diff_col).sum() == 0:\n",
    "        print('Output of GA is already permutation matrix')\n",
    "        return x\n",
    "\n",
    "    # Greedy procedure: if the max on rows is the max on columns then this permutation is in the solution\n",
    "    x = x.reshape((n, n))\n",
    "    max_row = np.argmax(x, axis=1)\n",
    "    max_col = np.argmax(x, axis=0)\n",
    "    row_solution = np.zeros((n, n))\n",
    "    col_solution = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        row_solution[i, max_row[i]] = 1\n",
    "        col_solution[max_col[i], i] = 1\n",
    "    diff = np.abs(row_solution-col_solution).sum()\n",
    "    if diff == 0:\n",
    "        print('Greedy procedure successful: no conflict between rows and columns')\n",
    "        return row_solution.flatten()\n",
    "\n",
    "    # Randomized method based on Sampling for left vertices\n",
    "\n",
    "    X = row_solution*col_solution\n",
    "    unfilled_row = np.where(X.sum(axis=1) == 0)[0]\n",
    "    unfilled_col = np.where(X.sum(axis=0) == 0)[0]\n",
    "    if unfilled_row.shape[0] == 1:\n",
    "        X[unfilled_row[0], unfilled_row[0]] = 1\n",
    "        return X.flatten()\n",
    "\n",
    "    prob = x[unfilled_row][:, unfilled_col]\n",
    "    prob = np.apply_along_axis(lambda x: x/x.sum(), 1, prob)\n",
    "    r = np.arange(len(unfilled_row))\n",
    "    c = np.arange(len(unfilled_col))\n",
    "\n",
    "    current_obj = -np.inf\n",
    "    for k in range(n_sampling):\n",
    "        new_X = copy(X)\n",
    "        proba_row = np.ones(len(unfilled_row))/len(unfilled_row)\n",
    "        p = copy(prob)\n",
    "        res_r = []\n",
    "        res_c = []\n",
    "        for i in range(len(r)):\n",
    "            new_r = np.random.choice(r, p=proba_row)\n",
    "            new_c = np.random.choice(c, p=p[new_r])\n",
    "            res_r.append(new_r)\n",
    "            res_c.append(new_c)\n",
    "            proba_row[new_r] = 0\n",
    "            proba_row = proba_row/proba_row.sum()\n",
    "            p[:, new_c] = 0\n",
    "            p = np.apply_along_axis(lambda x: x/x.sum(), 1, p)\n",
    "\n",
    "        for i in range(len(unfilled_row)):\n",
    "            new_X[unfilled_row[res_r[i]], unfilled_col[res_c[i]]] = 1\n",
    "        new_x = new_X.flatten()\n",
    "        new_obj = np.dot(new_x.T, np.dot(W, new_x))\n",
    "        if new_obj > current_obj:\n",
    "            x = new_x\n",
    "            current_obj = new_obj\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40M3WSl9sv9N"
   },
   "source": [
    "## Computational cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jx3-ncbQswRB"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQAB36jq2U98"
   },
   "source": [
    "## Bistochastic normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukSVhkqRBXtr"
   },
   "source": [
    "The second contribution of this article is called bistochastic normalization. Before giving more detailed information about this method, let's see the motivations and intuitions from which arise the need for normalization of the compatibility matrix $W$. To illustrate the need for some normalization of $W$, the authors consider 2 examples. The first one is the result of SMAC runs on real images. More precisely, they extract a set of feature points in two airplane images and, for each edge of plane 2 (top-right), plot the most similar edges on plane 1 (top-left). Blue arrows indicate edges with high similarity. We can notice 2 main groups of edges: \n",
    "* edges of type \"1\": they correspond to roughly horizontal edges in th 2 images. Horizontal edge $e$  (zoom on bottom-left image) from plane 2 has many correspondances with edges in plane 1. This edge is described as an *uninformative* edge as it can not be used to match a precise and restricted set of edges. \n",
    "* edges of type \"2\": on the contrary, those edges are considered as *informative*. They roughly correspond to informative or *distinctive* edges. Indeed, most similar edges (blue arrows in plane 1, bottom-right corner) are grouped in approximately 5 distant locations. \n",
    "Despite this clear distinction, informative edges contribution are \"outweighted\" by uninformative ones. This is due to the fact that $W$ is unbalanced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzKzL6vu2UuC"
   },
   "source": [
    "<center><img src=\"\n",
    "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxIQEhUSEBIVFRUWFRgWFRUXFhcVFRUVFhYZFxgVFxYYHSogGB0lHRcVITEiJSkrLi4uGB8zODMsNygtLisBCgoKDg0OGxAQGy0lICYtLS4vMC8tLTAtLS0yLS0yLTAtLTAtLS8vLS0tLS0vLy0tLy0vLS0vLS0tLS0tLS0tLf/AABEIAKYBMAMBEQACEQEDEQH/xAAcAAABBQEBAQAAAAAAAAAAAAAAAQIEBQYHAwj/xABHEAABAwIEAwMIBwYEBQUBAAABAgMRAAQFEiExBkFREyJhBzJVcXKBkbEUFRZSlKGzIzVCYqTRc5LB8CUzQ7LhJDREwtMX/8QAGwEBAAMBAQEBAAAAAAAAAAAAAAEDBAIFBgf/xAA8EQABBAAEAwUGBQMDBAMAAAABAAIDEQQSITEFQVETYXGR8CIygaGxwQYUFdHhI1LxM0JiJDRyshZTgv/aAAwDAQACEQMRAD8A7gagokmoU0iaJSJolImiUiaJSJolImiUkNEpNJooTZqURNESZjS0RmNLRGY0RGY1CICqIlJoia4ohJM7An8qIsZ5JMVfusMaeuHVOOFboK1GSQHDE0JXbQtgVnqfjUWpoJM56n41BJSgkznqfjUWVNBNKz1PxpZSgmlw9T8TSylBJ2iup+JpZSgkLivvH4mllKCO0V94/E0tKCQuK+8fiaWUoJC6r7x+JpZSgm9sr7x+JpZSgjtlfePxNLKUE0vK+8fiaWUoJO2V95XxNLKUE0vq+8r4mllKCTt1feV8TSylBHbq+8r4mllKCfbvKzJ7x84cz1qQSocBSulV2VwE2iKIMTZKijtUZhAIkbnYTzNZ/wA1Dmy5xatMEuXNlNKXV6qRRSiiIoiKIg0RNIooKSKKERREmWiIy0RJFERFERFERFETXvNV7J+VFK5/5ElhODtFRAAW8SSYAHaHUk1DiBuu2AnQK9xbi1hnRBDqswBShQ0lMgzsfd49KzSYprNGjN4L0IeHyP1f7A6u+aoLjjF9RBbShAy6pIzQqTqDpyj86zl+LeAWNA05q0RYGIlkjy43uNqr481a4FxZ2zoYdTlWoSgpBymEyQZOh0JHLlvE9w4h+cxyijy71EuAHYfmIXW3n1Hr1otMa2LzUxVFKy7Zu7h+4S3c9mltzKB2aVaGY+X51uPZRsaS27WIdq97g11UVGtLh155du1iiFutiXEJbSrIJjUjSZ5TNc9rB/8AX8112c396suHLh4uXDTznaFpSAFZQncKnQeoVGIawNa5oq1MDnZnNcbpXhrItKSiJqqhE00RIaImmiJtESVKIqET7bz0+0PnXQ3UO2V8quyqkxYkEHmIqCLFLoHmsHhuEpdTcMGUuIXCXIgpkEJOp1Gkx479Pn8HgY5BJE4ag6FfQ4nGOifFMNWkajl3qXaYo5h7lvbXTpdDkgLgqOaQNSTMAkdd60tfPhpQJDbD5+gqX4ZmOZJPA3Ll5XpXody2KTNeuDa8RLREURFERREUUIpaKuxbG2LXsw+4E9ovIjcyrxgaDxOgmuHSMbuVdDBLNm7MXQs+CnJcB2IPqPWpa9rtiFQHA80412pSRUIjLRSiKIkiiJr47qvZPyoi5l5J8ORdYEhlwqSla3JKTChD2YEEgjcDcEHY1y8A6FWQyOicHsOoTOLPJog2zi7Vx9VwhRcZBcAA2lsAADbNB3mNY0rZw6aLDyAZGhp0Om/rmu8ViJ8RrI8mtlmuHcQFwwlepUBlc0/iSBJB8ZB99d4/D9hOW8jqPis8bratFbNOJR2jOUOpMpJjny102r5fiOIDJ2NAObqNwvc4fkDSJbyHdbjBcUS+jKVoLyAkPJSfNWRrp0kGvQwuJGIjDxv6+qw4nDmF2gOU+6TzCsDWhZln+Hf/AHF7/ip/+9a8R/px+Cywe+/xVDgNuyzjVw2wlttAsWQlKAlKZ7TkBzrNyWgVavMA/wDc3v8AiI+S60zn+lH4KiH/AFHq/rItKaaImqqETTUokNQiaaIm0RJREURPtvPT7Q+YqRuodsr5VWFVBeS1gbmOVQugsai5Q1iakpWCl9sKEQQVRprP8qv80V5bKZjSQdHC17To3ycNDiNWGvgtE6ylYhQneDzSSIzJPI+Nek5gdoV5DZHM1HrxVHZYc9h7Ck2qlPBKVKS2s6qUTJiI/wBzXlvgxUL80TrboK6dSvUkxUOOmBnGS6BI6KwwrGX1NoXcW5QSCVATpp0O3v6+FVScTnicTJCcovUXt8VRiMJC17mxSWOSluYuAJy5QSACohIM7DXnVX6xM8jsoDV89NP3+SoGG5ZvJZbFfKA3Cm7dKnnMmYFoFSQZjU76b7RHPWqDNjsWzI8BoNbXm0P32Xr4fgb9HykNbf8AuNKVwDdXrrCvpnaJUlwhJcSUrUmJmDuATv8A2rXJhMbIQY5S1utg+HL13rNxhuFbOPy9URy2FfutEpB5uHltXDeFYo/6k55beGv8ea8gpn0ad1Kq0cGB96RxPiFWYwV53OEMry9q2F5TmTnAOVXJQkaEVpi4ZDHzJ+K6YCy8riLFGjuOircQ4cQ6+xcpcWlbBOVIPdM7k+PXqNDVn5IRj+kaPerIpXwQPhiA9qrJ1Pw+yLK1vy6/2z6C0SOwCZlMDXNoDv4nwgV12Mp3cqp4WPhiawuDh7xvfavjv/KThzG1tISziVw2blSl5QNCpI1EAACRqNtY5mrIpfZpx1Xcs8MvaTQNcGMq75H5q+VijKUZ1OJSkCSVEDKAJJV0iDrVwcCLWWPGQyZcrtSQAOdnlS9MPv2rhtLrC0uIV5qk6gwYP5gipBBFhbHscxxa4UVIouF53HmK9k/KiLnvkQ/dDP8AiO/qGocum7LdmuV0uK43hpw/FFNJks3QLyBuUr1KvE6hX+YdK96VzMTw/tXEB0eh8Nh66qlrXCTKBa04UktCDruR0g6H8q+DxruyxkcsWp2r5L2oGmSB7XaDqoWFXa2XkqaKG0qUe2JTJWnkD+e0ama9PFYWWJxlg1NbKIsbHJAYsTZI9zoPX0W/YxJCxMjlsQd9vjXnt42wGpmOaddK6LGYSNisVb48ULunm3GG2+3yqVcSgZu9AB0E76b+Fe9Fj8JMGMcTmrbr3+Hes+K4ficI7MctO13vRZ63uMOafaDYwoOFWZtaSopStBBTKwqEGSCJiYNabw1X7Sy/1u5dFwCydbW84+UZnVJMIJI7uad/X+VZMRj8I4NYx4003F67aXzVkMbmlzn81cKUOtVOkY0AucAD3q8kDdQrzE22/OUBrG/OJIgc4rLJin58kbb7+SofM7NlYLUHhnGl3aFrcZLULUlIJnMkR3thzMdNN6vjlzOLSNVsxDWRSCNr82gOnLuVxV6rSGoRNJopTKKEURJUovS389PtD50HvKHbK9VVhVYWF8oPDV9drbcs3W8qUhJYdzBGbNq6FJ5wYPgnTeuhFh5QGzg6G9D8itWFxkuFLjFWorVZvge7NvfKscRt0IukpzMupzFC06qJGY7xMKHJJGhGtz+EYaOMYjD6jY3qQupuK4mYFkjtDyG3+F0wqrOsiULA3oO5QUx66SkEqUEpSCVEkAAASSSdgBQMzkNAu+5Lpc0xLDbrFb1ZQT9FafQlSVuHsylOilN5dCSJPUdoNemWSCQvp4IHQ6ady+khxsODwrezIL3A6gajuJ5LomH2LVsClhpDYJJOURqoydfcNPAdK0NY1mjRS8GeeWc3K4nbdSe0mulSDyCCaUpRmjnSlBNLx+mIJA7RJJ2GYa6xprrrpXZieOR8lV28VgZhZ7woysWaE96YJGgPKrxhJTyXlycfwLLt2ovQA8vseSQYqCYQhatuXUSKg4Vw94gKn/5BE52WKN7tuVbj7+CiuYcp9xDxtkZ0DuLWO8nNor/ZGnKqzDCDrqUZjuKSsLY4g1rqLgeZvX10C914I45mS4G8qgQoRII2iOhH/mqy1gVDOG4wy53FrTd2ORB0rorfCMNbtWksspyoTMD1kk/mTXIAAoL6bM92sji4ncncqZRF53Hmq9k/KiLnvkQ/dDPtu/qGoJ1XTdlu65XSxnlJs7lTTb1m0lxTSypxMS4pop1QjmQTBIGshJG1bcHDhcRmgxZIa7boHcifn80E0kLg+PdZmx4vswot3bDlq6ndDmYjx5cjMSOU1Lvwl2ZE+GqQa0QfqPVK08TkkaWPO/ctLhWI20lTJS5Ejz0qG8bBOmx+FZpo5ojUjSPEKoZXbFXLeNAqgJSkRuCN+kRVBIcbOqUqDFePmbd9TBtVKMIVmAACyqCYka89eZBFZJY4MwJZqKqvW3cvUwnDZMS3MHgDv5KO7xpaktvOWC8ye1CFlAKmxoTlJGmaEzB0g9KqfHhzGWFpo3ep9eHRXN4JI52VsjSdOfXzSL47L68tlbZkgpzrWrKMp0IA/hPjJ2OhrBLwzDv0haW7a2fQ7127hEcUZdipQ060Brr4/wAKZe8QKMpbR0gmJB593UeFXwcKOVrZnWG6VyXzphze8qglTqipW51Ogr12MbGwMbsFcGgDKNlKwriLsnm7cNkhWaXAO6I2zSOo30iRvVD2lkmca2FyMJTJMU12oHu8z4K8Vjtx9KbbTbtrYKCVuAwpKhsIn2eWub+U12JX82qtjz+WdI8HPYAb3ac1bDEB/E1AjUirGvvcLzv1CRozSRkCrUa3xq2fQXGVhQCshy6wqdoPuPq1roODtl6kjxE4Nk9kmqB032/nv0XuhUgEc6LuwqXFbl83CGWXAjM2VElIVqCeoPStcLIhEZHi6NLNK6TtAxhrRZ+84pSy/wDRnMTZS7OUp7IkJV91SwjKk+s1Idh/7D5rnLN/ePJaDDX7lu8aZedSsLBVokDaY1AHMV0WQujL2Nqj1UB0jZA1xvRbtVZirwmmoULIeUHgZnFG5PduEIUGV5iEydQlehlMjpIk1vwGOfhn/wDEnULlzQQqK34TxxwJS/iSG0pLerYJWUhspXKsokzG8gklWkAVsOL4e2yyEkm9zpvp6HLTvXOV55ryxPyWPrZMYlcOvBCMgcWoN9ohWaTqSBEgcwdZO1XQcaja8XC0Ns3Q1o+vjsoMR6pf/wCRpUySu5dVcrS4pZK/2JedSMxyhIUU5h74EzEV3/8AIXiQZWNDAQBprlG2vX6ck7HTfVZ664QvcFY+ki5js7hJSloLUgpWmFLcSYHJKYOmp1EivRHEsNxKXsjHqWnU1d8gPXTos7mPibmtdUt8SbubZT9qsHMhRbUoGAsAiFJ30UNR4V8nJAYZ+ymGx18FpL88eZm9aLHcH4Z9PaVcNXzgcUVh8JBAzk9w8u6UwdB6iIr05uJQB/ZtjDmtNC/msH6ViGAPkeWlwvz2WkRweuZN4+dQTrr5uXed559NPGs54i2q7Jvo+vio/TH3Zld593r4JzfBwMBy4dWBl0mBKZ1gz7umu9QeJEe6xo3Vf6OHaSSOI05pmJ8LtNtSyFZ06jWc3emCPAExHQb11DxCR0lSEUVkx3A4xATADnG3fqrHh6yhpPaNAKBVBIEkHnqNNNPUKz4uW5Dldor+DYEMwze2jAcCd99f40VylIGwrHa9xrQ3ZE1ClFERRSkootMfPdV7J+VEXPvIj+6Gfbd/UVUO3XTdluq5XSaaKVAxPB7e5EXDDbsCAVpBIEzAVuNRyq+HEzQm4nlvgaXLmB26yF/5LrQqz2zj1sokE5FSmBOgB1GpTzMZdBrXrx/iDEZcszWvH/IevRVRw4/26Koc4Wxa1kNON3KBMZjC4CeYUQZJ0jMdhqJqx83CcVq9pjPdt5Dw6BVkTs902FVqubtu4LlxaOZkIypAaJy6gZguNUyVagkawN6yngsckuaKZpZyvfvW08WbHhOxDHBxOtbKwVxMNQpDm60kFMaoEqBnpOo5c4p+hTH/AHN5c739aLzv1GMcinW+MNqMJSElWplITJI38TEeus0/CcRCzPQI7la3ibJnBpJvlf2Xs3cJzgKIgjeOfrrOzDSSRmRo0C6kxUccgjcdTsvS4dSPMM9a7Zw/EPF5VRJxTCRuyueLTC5m3Hv5/Gu/07EA1Sp/W8FV5/kVMtXyjzQfHXWq/wAjiP7VJ43gQa7T5H9lJF+50VXBwkw3au/1bA7GQdOfS96peVikMApaZCBJUQkACeum/L4QNqhuFlZs1Z8XxHh2NIdLKCdADZB5gevAmlTO4o5bMPptLkrfcfCEBZDnZuOKCQkJJgEDMc2wymRpFVxMq+t+S14ub2433lYIxsKDwP8AdflQ316EFX2EIdQ9aouDLqLUJWqSc60hQUqTqZMnWtpaBh3Ueaows75pMz2Fu4F7kdSqjjEN4k8MMYCAhDoevXu6kN7ns0nm6qTPTnzjEOq9I9FqlH/iNt7B+aq1xf8Abu8Vnk/1x4LcqrOVcE2KhEUSklFKKIiiJrrYUClQkEEEdQdCKkEggjkoIsUuY4Zwni1oCi2fbS0hxam0qWSVggASMmXUDYwJKj419JNxDh+Ip0rCXEAEgbda1v8AjReaIMSzRhFLX8F4AbFlQWrM46rtHIjKFkAEDrtvzrxcZNFJJ/SaGtG1c+8rbEJQ0dq4uP0WhmsiuRNEXk63moienQRREtERRElERNESUUJj3mq9k/KiLn3kUP8Awhj23v1VVDt123ZbmuV0kJoibNERRElQiJpQReZSOnX896myooLP8XYF9JbBaQjtUqEKJynLsRPPlv00r0uHY0QPIkJykFYcfhTMwFg9oFVWG8JKWgqeUW3Mx0GVQygaHfrPPb11pfxKOGoohmZXNYBwyTEf1JDkd3LSYdhTbKAnKlShuspEknc6zGmleZPinyPJsgcgvSw2BiiYAQCeZrc81J+it7ZEch5o2Gw2qvtpP7irfysNVkHLkOW3kvM2TcR2aY15Dn40GIlu8xVR4fhS3L2Yrw67o+io+4nrtUnESn/cVH6bhLvs273smi1QP4B8Kk4mU/7iq28IwLTYib5fuq7DeH2WFrc7NBWpwuZsgBSrKU93oYUraPOPU1RzJ6r0TrG2M6hooDoPX26LyxZh8XCHmWwvK2UkFQTqSepHWtkLouyLHmtVmmbJ2ge0XoqK54aS4tTjmFW6lLUVKUVJlSlGST3tyTTJh/7z5LnNN/aPNXmE2z6rplxxlLaGxkACgRGwAAJ6/lXRdE2IsY67UBsjpA5wqlvlVmKuTahTaSiWiiWiaKUk0UWiaJaJolpKIlopRREUUIopSGihJNFKKIiigoopTH/NV7J+VEXPfIqf+EMe29+qqoduum7LcTXK6SGiJKIioRJNEQaImk0RNNEQaIm0RIaImk0RIahE01IRJRElERUIvS289PtD5ipbuodsvPi3FsQYUgWGHi7SQStRfQ1kIOghW89auVSoPtPj3oNP4xr+9ER9p8e9Bp/GNf3oiPtPj3oJP4xr+9ER9p8d9BJ/GNf3oiPtNj3oJP4xqiJPtNj3oNP4xqiI+02Peg0/jGqIkVxRjvoIfi2qIk+1OO+gh+LbqES/anHfQQ/Ft1KI+1OO+gh+LboiPtTjvoIfi26hEn2px30EPxbdSiPtRjvoIfi26JaPtRjvoIfi26Ij7UY76CH4tuiI+1GO+gh+Lboia7xRjuUzgY2P/wApvpRFkvJnjGKtYe0i0wv6Q0FOZXe3Q3mJcUSMp1EGR7q5LV0HUtR9oMd9Bj8U3TKpzo+v8d9Bj8U3TKmdJ9f476DH4pumVM6Pr/HfQg/FN0ypnSjH8c54H/VtVGRM6Pr/ABz0H/VtUyJnSfX2Oeg/6tqmRM6Pr3HPQf8AVtUyJnSfXmOeg/6tqmRM6T67xz0H/VtUyJnR9d456E/q2qZEzpPrrHPQn9W1TImdJ9c436E/q2qZEzo+ucb9Cf1bVMiZ0n1xjfoT+qapkTOj64xz0J/VNUyJnR9b436E/q2qZEzqdgeI4su4aS/hPZNFYzufSW1ZE75so1PqpkUF1ro1drlFERREUReb57p9VcuIAsqRuqw3CQrKVpCvu5hOu2lV5x1V+R1WBp4aJ5qbXKKWotIaWiSlpaJqbUooiJpaLD8QXN21iuHp+kq7F9x4dglORIS20kjOqZcUVKJ1gCBA3JnkuTuukWnmj3/M10Fwd17VKhFERREx/wA1XqPyoiwfkL/c7Htvfqqoi39ERREURFETHjCT6j8qgoq1L3jXFq2kPXASJUdKi0pQfp7KxmS4PzolJQudjPqNQlJxUetFNJMx60REnrREFRoi555TWH2G1XbWIXSHS42i2tm1ZW1KJSCjINXVGFqk+qK7aVw4LqmBFfYN9rGfKM8bZ470eEzXQXJ3VhUqEURFERREURFERRFV8T3CmrV5xAlSW1FIidQNNBvWXGRtkge12xBWrAxtkxLGP2JAK4A9crWsuKUSsmc06z1B5e6vFb7NAcl+osijZHkaNOnJdf4NxRx+1Qt/VRkZoiQkwCesjnVQ44IMS6Oc22rB6HpoNl8BxXBxw4hzItlbm7QDClJHrIqcL+Imyyhr48rT/usnw5BeaYwBug3iPvp/zCrsfxtuGk7ONmc86NAfI2oa2xus5hXlBsX3nLYu9k826trK5CQsoWUy2vzVTGg0PhXpTYox4UYgMJJANDez393guBV0tQFV5nD+OR4qQxvGU8tbv5BdObSMwrZ+rYXtuxz67c689lFIKh1rRi8ZDhWgzGr8b8goWN4i4evrm7ZuWri2Qm2UtTCVNLUf2iEpX2hCu9tpEV3BjYJYu1YfZ9dVyQV0DDSezTmIJjUgQCecDkKtw2IZPGJI9iuHbqVV6hFERREx/wA1XqPyoiwfkL/c7Htvfqqoi39ERREURFEVbxK8pFpcLQYUlh1STpooNqIOum8Vy800q3DtDpWNOxI+qwPBfFxvEnP56AM8DQzspPwOlZopM26ycYjm4TiA5zs8T7rqPLp8wtNe3YKcg16+FXgLz8ZxpkLg2IZuuu3dsqVmzIJA1HhoahauH8SjxQrZw5ft1VjZNupnQx4k1C9JWCTpr8qlEtQiDREGiLGYpwxeuXxvG7i3OVOVhDzS1hgEDMUBKgMxMyreugRS5o2ui4EFhhAdKSuO+UghJV/EUgmQJrpuy4durCulCKIiiIoiKIiiIoi87hsKSQdiIqnEQiaJ0ZNAil0wlrgQsXfeTy0W4XU5xJBLYI7M9eUifA15uKwDmw/9OfaA5r3ofxBimR9maPfz+v2V8xh5SmAAkAQEjaB8q+ZH4dxb2OfIadyG9/HkvOdiAT1WFx7yUWl/cruHHLhK3CCoJUjKCEhMjMgkaAc61cL4hxABuFZGNOZBFeOoCqexnvEqC75DrBJ/590fHM1/+db8fxXiGEkDRG1wOxAdr8+SrZGx3NZzC/Ik8464p9zsrdLiw2JC33GwohKjHdRKYMnX+UV6k+NmZhBOxmZ1Aka6adNz4LgNF0uv4HgqbVkMtZyhAgdotS1eqVHQeAgDpXxJw2Nx8j5stEdBl+A+GvVX21opSa8otN1WqhC2yncRNehjYcTGW/mL2FX06fDmubQEEiY0G9cQxTmJz2A5Bv0+K5KtMP8AMHv+Zr7jgf8A2TB4/VVlSa9dQiiIoiY/5qvUflRFg/IX+52Pbe/VVRFv6IiiIoiKIqzidtS7O4SgSpTDqUjQSS2oASdBr1rl4tpVsDg2VjjyI+q5zwpgKbJBlWZxcZyD3RGwT6pOu5/Ks0bMoWXiz5+LYgCRuWJl1qLPfptdbctlf1eDovjcfgH4WSjsdilSvKZB1/vXbRaoa6XD1INLuj3c1zjinja47VTVstbSW1FJUD3lqSSD6kzMDnuegxyzWaav038N8AZFA3ETuzue0GrNAEWPirXgTj64UsWtx+1KirI4fOEAqKVHmNDB3G220wyZjlcrPxDhjhMOcVhwPZ3Bvw0810e1uEujormP9RWpzMq+d4bxRmLFHR/T7juUFzHGBcC17QF0oU5l6JSoJ1PUkn/KajIVp/PwUTm0By3yvpfqtlYVytiUVCK3w3zB6z86sbsq3bqVXS5RREURJNRaImloiaWiJpaLyulwhR8KEqRuoKroJEqIFVqykLuwBKlADxolJVXYEEkCdpqbSglXdgbkD/WpSkpuRMEgHppUWmVL9IExInpU2lJmdM8p/Osv5PDCTtcgzda1UodcTGpGmp8PXVk0MUzcsjQR3oAb0VZjGNNWzSnFOJyjSEkEknZIHWsWLBiw2TDADWvC91ogwU+IkETG6nqNAOp7lK4QxX6VatvFOXMV92c0ZVqTvA6TtV/DYuywzWXa5x+E/KYh0JddVr4i1c9oK3WsaO0FLRHaClomPrGVXqPypaLC+Qv9zse29+qqpRb+ai0RNLRE0tETS0UbEz+xc/w1/wDaag7KRuufJdHWqVcnh+lInJuRUtJbsseNwMeLZlfvyPT/ADzWL4o4R7RztbUgFZJWhRgZjqVJJ69P9imWME21e3wXHTYeAQ4og5QACBy6FTeDuFAwrtniC4JypSe6idJJ5kifAT12tw8QHtOK8L8V8YxErfy0DD2btzV3zruAWsubktoWtAUpSUmEJ85X8o8TWrO3Nqvk4OGYkQma8t0P/wAncnoKXC7PE7tOKfSHW3C6lzM82EKUUNGEqTlGoAQoAe6gJDrX0L8Ph3YHsWkZSKHj/lfQVvegJAMn4bcq6fAXOsLxcBxxuGhEcoLnA8q0HS/FTWHQsSD7qoewsNFfT4PGxYqPPGfEcx4q7w5QyD1n51Ldle7dSc4rpcoziotEZxS0QahSElFKKIiiKNiRhpZ/lNQ7ZBuuX+U7H3GGG229FOlXf5pSgCco6nPvyj4Z5H0F63DsM2V5LuS5xhHET7C5K1LSYCkKUSCAZ0JnKfGqWvLV7E2Cimblqu8KdeY5cOudqp1WaQRBhKY2gbCKzOlcTdr3YuH4eOPswwVXn8VJxriW4uylTisuUQAiUieat9zUyTOduq8HwvD4YEAXfWlbWXFb/wBFUVHM40UJbWd4XmjMP4inJp6xO2tjcQ4RlebPwWB+LYRo11kgbaV9VS4dj1wy8HkuKUoEkhRJCp3BHjVLZXNN2vYn4bh5YuzygdK5dPXNXN1x1cqf7VsJQnSGzCxA3BVAJnXaKsdi3k2Nlgj/AA5hWxU8kn+7b5f5XhxNxmq5lDQUhCh+0BIknmkRun4T0FdSzF4oaKnhvCmYWQvlpxG37+P0VDbhSyEoBUSdEjWT4DrWOjdL6Yvja3tCQB1XbvJwkjD2QQQZd0On/WXXsYXSIBfm3HXB2PkLTY9n/wBQtLV68hFEQKImvear1H5URYnyGfudj23v1VVJUrfVCIoiKIiiKJixhh7/AAl/9homy5mlSiJCTHWDFQInkWAa8FzJjMPG/I+Rod0JAPlaVtSlebrRkTpDTQoxWNgwrQ+Z1A+tkOLUkwoRSSJ8Z9oUowuOw+KaXQuBA3/wUjjpCSsg5QCSqNABuSemlQY3VdGlZ+Zh7Tsi4Zuli/Ct162LqHZ7N5tRESEqC4mYmD4H4VbHhw8WHC+5ePjONyYSSpIHht1mcC2+tAjVe1vJUUnSN6iLDkvpy6x/GY4cM2WL2s2g7ut/ssZwOS5ieIu/dUWwfDtFAfk2K0RNBc4LyeKS9lgsPYs7kcttfquiVfuvly1zRqN/L/CmYcgyVcoj11lxDgRlX1P4cwsoe6YghpBF9f8AC0Vl5g9/zqgbL6x2696lcoqESg0RexopCi4hfNsILjqoSNJ31PhVcsrYm5nKyKJ0rsrN1VYdxdavHJnCF/dUdhOhnaDBjxEVW3Eey1z2locSBY0079r1281e/CPBIbTq6fsr1KpEitANrIomMmGHPZNQdlI3XPcbsW7tktupnQlJ/iSqNCk/7mqHAELZh5nRPBaVyNFmUnWZGkRsRvWBzzsvvIsO0e1d9FpOH+HDcoLillKQqAMvnRvBnTmNjXccGcWVi4jxj8q/s2ts1ve3yV9f8IocUOzIa0iAnMDHPca1c/DNO2i8jCcfmiBbKM+vWvsVY22ANJYSyUZpVK1bFXjI28OldthaG5Vin4piJMR24NEbAch0VU3wUkKJLhUkE93LlMcpUD/oKqGFAOpXqS/iWUsqNgDtNbv5fyqu64UfCyltOZHJRIGniN9PAVS7DPDtNl6cX4hwroblNOrUUT9lQXmGusudktJC9IH3sxhJHWagscDSvixUUsXatOnq/Jbfh7BBbJQterhkq6IH3R4+Na4oQ3U7r5fifFHYj+kzRg+fee7ouqcPKzW6D4q/JahWtuy8J2ptWEVK5SZaIiKImPDuq9k/KiLE+Qz9zse29+qqpKkLfVClMddSgFSiEgbkmAPWTUOcGi3GggBJoJyVTtUg2iWiKNiQlpyfuK/7TVkfvhZcc4tw0jmmiGurxorDJEDSvfAAFBfkj3ue7M42TzQ22E7CJ/OqwxrSaC0z4iaau0cTQoX09fyh1kLEESN65kY1zfaVmExU2HfnhJBrWvv60WC8o984FoYBhooCyBoFKzEQTzAgaePqjxOJSPDhGNG0v078BYLDyQvxjhmlzEWdaFN1HeSTZ57dVksLvnGHEuMkhQMADXNP8JHMHTT1V50b3MdmbuvucdgYMZCYcQLafl3jvXe7SyluViFHUHpptFevJiPbsdNV+VYXgJdhHRTaEuJb1GlC/QVRgfCLdo48tuQX153CVZupASI0EqVvO9BPGwEt3VUvCsfi3RsxGUMbpY3/AM6BaUMpgCAQNpE1lMjrJvdfSMwGHbG2MsBDdrAPl06p/q0rlamtDQABStLEdwe/512Nlw7de8VK5SRRERRF7GikKr4ktu0tnUgSQnMNt0689tiPfWXGx54XAePktWCkyYhp5XXmueDg8XtulaVQoTlMpQQQYIUG0gKEbCUnqedetw/igMTSaNgA7u2/87PjYPdyU4ljsPiHBv7b/wDjl/ZT+C8XubV5NpfIdGZJKVKKSlKR5vmyAAJB70zvI1rFj2wYfE54XN7NwADQTYPM07l4UANwKVrIHYjDGU++DrpvfQjn4+a6K06lQCkkEHUEGQR1BoHBwsHRYHAtJBGqfNTahFSlBE1GZKRNLRE0tExbyQCSoADUkmAB1JoCiqsT4otLYw+8E6STClJGsalIITr1rTBg55zUTbPz8ly5zRuoOCcd2N2txDTwBQQJXCA5OxRJkiQRsDt1FJsJiIP9SNw7608wu3hjGh2YG+hsjxWiauEqEpUCBvHLwPSsjHh4zN1CgagFPmukSRREsURJFETHh3Veo/KiLDeQz9zse29+qqpKhb6oUrm/lmvVsMtKbURnKmz0TmSSFjodCZP3DW3hvCosbigZrLWi65Egjcc72+KvjxboI3Bu558+f0Xhg7mIF4qt05W83eSSnLkSEDLKtVCc8RB90GvKxvDRhBmwjrJG2+uZx1vYBtChr37r0MPi8PNG5uKGvIjwHT4k2t1gWNJuQsSkONqKVoBkp6Ejccx7jVWCxRnZbxlN1SyYvCOw5B3BFg8irJ9MpI3kH5VutYyAdCs+rAyTOVQ8ARFam46UNql89N+GMHJKZASBew2+i9l4WSACjQbagf61Q2eRri69SvUm4Xg5ohC9nst2rfz70NYYpHmo9eoPzNcySyPNuK7wfD8NhGlsTdDvepPd4LMcT8LuXKS2LcqHJUoBQY85JKq6klMrMrx8eaqwHDmYDFfmMM9zerdMpHQqLwfwB9FcLrjK1LEZCstkJOslISd9tTWVsQavosRxKSZuU6eC2ptHPun4j+9d0sAICX6Iv7vyqKSwvJlvPOSFQSkwpJhQ3SYOhHSgCk+zuvT6Gv7vyqaKjMFY2bZSgAiDr866C4J1XtFSoRFESZaInmiBeVwU5SFxlPdM7HNpHvmKh1V7Wy6bmu27rGcFXQl+3zSptZIER3ZykjnuB6pFefw9ro80TtKOngvY4szOI527OFXd6960N/aJeaW0uQFoUiRuMwiRW+RgeKK8uGbspGyNGxBrw6rG3fDuIWTU4ZduKy/9ByHEK3KsoUD2e5MAwfCtWExTGHs8XEHN5OZ7LwO9opp8dD4qycjEy5w7KSdbsjz1IUQ8V480mHsOSuYIU0FAxEkKGYxppMCD12PqiHg8jczZizfR/d30PHfUd2qxvbKxxboe8bKAfKffd6LRYyjTtBqYjz4CcsSJIGvIJrU3guEIBEzSD0OlcqOv1+JVXaOuqWexvyk37zqQ2VMmfNaUSVpVGQQcyZ15Dnzr08NwPBsicXkO5W7Sjz6H5rkueToFN4dxHHrx09gtaULEy7IaCU92cwToSQQcoEknQRp5DsNwDCMETASdzkuvrl+pWp8OIyZn0OVaX5b/AB2Wge4ExV4A3OKqkTokrHIR3hHMdOXWuW8S4fE4mHDCzWp1+X+PJUGN53KdhfktCSS9eOLPe2LiZUoqlxRCwZhR0/mMk1E/HS8VHG1o05NNActRt6FKBD1Ks7fyV4dqXEOOE7qUsgzuT3Ykkk71m/Xcds14aOgA26ag6eGveuuxavC/8lGHr8wONnUaKBAmeSknaZ9w1gVfF+IsYzQkHxQwtVS15Lri3zKtMScQrzk6KQCrbvFKufWDvGtXP/EDJNJMM09ev/qfquezfY10VXd2ONYcjOu6MK0JzBaWxupQUTmRtqQmNSZmK6eeHY9lNjyPA0rcnptR9aKWtbHMJHjMB9FtcI8pNolDbV07+1DaM60gLC1kQYDc6kgmANiOorzv0bF5czW7eI+oH2Xbp2E2BQ6dFfN8aYepRR9LaCgCSFLCdAM06+GtZX4DEsZ2hjNda09ealrw4gN3KubK7beQlxpaVoUJSpJkEVkHVWOa5pyuFFPe81XqPyooWF8hn7nY9t79VVSVyt9UKaXM/LuCbNoJP/VKiOcJSe97iR/m8a+i/DeU4k5v7a/j4qmb3VoeCn+0smHJkrRmWQZlR3M/791eNjNJ3gciR4UVfly0DzCj4tgbjQW9hoSh91YzkkRl1KsoOgJVlJ8M3OvJlwvtdpGTm8a8fXcvYw+PjeWxYwksaDXj310F/GuSnP8AFiLZsKvElCpCe6kqBVGpHhoazYfiZc4slYQRfkP5VUfC34iQjDEEb7+SuLfFWliQrlOumnvq2LiuFkNB9eOixPw0rNCF6rvWx/EN4661MnFMIzd4+vr4+C4ETzyUK8x1lDZWViMhUJI1AEmNdf8AzWV/F2Sf0oQQ8kDVpABJrXw3+6tZhpHH2RfhqqPhDjgX6nEdllWiFATmlBMSSBvMT6xU4jG4nDMacnacrGhsVqW8g69PituP4Z+VDXZrsDlsenetKX3PuDnVIxvEnHKIQN+frz5ryjXJeZdd8OXSumu4sRRDRp3Lj2uSbLyj5wG/wqwRcRe72nACzsuCJDzVLgPDCbEOBhxf7RRUqTMaQEiOXidauOEn09utNaWjHYifFlpeQMorT1/hR8KxXELZh9V82l1aCVNhvmgAnLIG3QmVRvJq0TSR+xlJ71ZO7DOxEcOGsA5QS7YXz9fJPf4ueTZi9+iLiBLJMK7yss5omOYMbRp067eS81aKtuHe7H9gXNDASM3X+e6/itTY3PatocylOdKVZVecnMAcqvETFa2mxa4JHI338l71KlFESmpXK4hxPw9ja3XlOM9uO8oLadCUqSFEIHZghXdSdE8xO5mfWwkfD7zONONe80Oqul6C+tEjcUtQx0rY2xgaC9iRd9SNdPGuq0vkqubFbBVbI7N0HK40pWZaOYCSQCUmJmJJBBkis3EcLMzEGWZxeTs7u6DkAPBVuxTpI2xgANbyHXqedlbkqrCFWnJUKlEFzpUeKLlXlDYuL+7UxaZ1lptOdonInU6qEkAjvJ6eE61EOLmgkIh6dPXzXvYaGCPCNknaPadob122PPy+K2nD3CdpZgKbt054QSVftMq0Dzkk7GSTIjfkNKuknlmdmlcXHvN+XIfALyZMS4jI2gNfdAG/XrXKytCXid6rWZNzUpShJqKRKHCOdEXhcXKEarUB6zVjI3PNNFqqaZkLc8hoKqv+LLFj/m3TSd9Acx0mYCZJ2I0rXFw3Fy+5GT671w3FRONNN8tj9apZ+/8AKtYp0ZDr/sIKRqYjvgc4HvFehH+HMWRclN8SPtaHEA8tO9ZPFbJ6+eUtnCUpUuU51qUsDuwF5E90HKROh1yka61uwbcNgRZxLiNNBt8/471wZi6MRtbo2601816YF5JrhxaVXSUoQAMycwlfQgo83lM6++rsZ+I2BjmwWSefTxvf4aLLIJyKjbrpvsuy4JhbdowhhkQhAMSZJJJUST1JJPvr41eq573nM82eqlvear1H5VCLC+Q39zse29+qqpKgLW8Q4kbW2dfDanS2gq7NHnKj5DmTyAO9dRMzvDbq1BXCeK+NxfFIW6gAIdSkBCoHaNrHe6nVKfAwTtI97gUGJiP9ZlElvyePtZvnstWOGDbpA4nT7H70uk+ShhaMOb7RXnEqTzASQCkDmNN55zWHjDGtx0uTYm/A0AfM6rOJjIxljYV49P2WumvNpF53Vm08nK8hCxMwpIUJHPWuHRsfRcLpWRTSRG43EeBpNdtGz/CB6tP/ABXnT8IwkorJXeNF03ESN52uT8U4w6b9NswckXWVDmYqTLjaGlJ0EAJC9h3gVk6GvXw8WFw0JYGAW3mLsteC2+4m7HRvgvQiwrXM7V5J5kDShR+wFctVqbHgBJKTe3C38gKEIEpSG9co1MpgmYGggDlWEYW3l7zZJJPLUrS7jnZsyYSMMFDvOny7td1psHwW2tJNu0EEgBSpJUoJ6k/Exua0Njaz3V5OIxk+I/1XE1qOisVL8fhXaypqFRUUpTw6OlSi8yqiIzUUWmXC0lJSSBIg6jSdqgx5hSz4h0LmOZI4AHTz9aLHdi+Ll1X05XYHKhLWQkJKYUqATG0gKG5Vr5tWR4QsaM2uh+lN8jZPXZedNxPAfk24e9Ru4Xrv8jpXgp91eXDzSktuqQshQQoDVMgpSTznbTkT4VzJG5ttBXmYfirmzsJJeGuFjax00/wtFwzaPM2rTdy72rqUwtzXvakiSdTAIEnUxNcNBAor6+SUSOLw3KDy6K0NdKtIag6qVx3jfgK6tn1XuFla+1dBct0CCmeehhaConSO7M9SPpOH8ThdH+XxIFVoSqHMI1aoFoxxKqAG3NErRLhbElBnN3laGYCTseWkmtr3cEF2eYOl+q6rkdqnXeH8TNoJzuKCcqyEKbUqdTlAjMuNiBIOm4qY5OAucPZrca357+XNCJU+7wHiUoC+2USqVFtDqUqTnEFJGiRHIA6coqIsVwMPy5KAoWRpp8b/AHTLIqS3OOYfmWvtEABtay6pC5SicqZUokiNClOulbXjg+LIaKJNgUCPXdei4LpWjuGq7Xw9fC8Yae7oLjaVKSk5glRAKkT4EkV8TioTBM6PoTvz6FamOztBWMx7FsQcuHRZ5WxbEJUl1xtKVhaiAshREyIjppGpr2sNh8EyFvbmy/XQHSvNecXTySlwsNbp4n6bKM+riJ0yhLKEhaoKUkApjTz+8pPTSST0GljW8FYPazHTu+3NX1KTz0TWOH+IVgldy2k5YAK4M5ht2YiYkydeVdOxXBmmmxk69O7v+idnKNifNR8S4Yx1sqX2wWnMSexdCDBEFSi7EaAfe/1q6LHcKcAMlH/kL+n8Lk4dx94k/FZzCcGduHeyvS+OSSpDhTBV3lJyEIVqNIMeM6V6GIxMcTM+Hy99V99fl8F5mIlbhCxrRQJ2G/wG/kun4Z5LsOa1W2p1XVSikeoIbypA6aGvmpuO4yQUHZR3fubPzXuCJq01hglsx/yWUI9QGg6DoNBoK8yTESyG3uJ+K6EbAKpT6pXaJolIoiY95qvUflRFhvIb+52Pbe/VVUlAt7UIqHifhS1vmHGXGkArJWHEpAWl2AA5mAknRIPUCDpV8GIkheHNP8hcloK5hwrxW9g5+gYs0psJQVtrHfVH8KRlJCknKoAg6EAHmR7+Mwbcf/1GFNkmiPv9yqmOyaFX1x5WLEEJaQ+6SpA7qAJziTlkySnaCBJOk71lZwLEkW8hu+56fv8ALmu+2Cr7jyrONEF7D3G2yXUyslKlKbGiRKQAQSAoaxPhFao/w+2QEMmBIo6ba78/iOvNcGYjkvPEfKNiDbWc4d2XcSrtHA5kBLmWYIE5tgJBGp1Aq2DgOFfJl7bNqdBV7fHbrsoMzgLpVPB3GFuwoLftAO0fJcfkqSzv2ZbSoGCAtcwZjXXYc4j8LhhcYX2QAQDud7+H3Wmfi804a2TYaaadP2C7SGydRtvXy4UaLGOcfMi4LSEFbcpSFpmVLVJhII10SrTcxOxr228EkMOdxp29Hp65rzX8Ryu0aS3a/L91ITxgVgFu2cUIWZ5SjoQCCBpPSa4/Sg335ANlQeLE+5GT69WvVHE7kx9Fc/g6z3xP3efLr4Vx+msq+1HP5etVyeLSg12J5df28vmvVvEb10wi2yjviVA7p21MDw8TUHDYVg9p97bKs47iEhqOIDfe/V/IqE9i1wtxq3VCHFPJSTqIQBK9NtgecGR77hhYWNdK3VuU+axfncXin/l5PYIOpGm+wI+ffstEnBXD576iJVtzBrEcSwe6xaf0bEyH+riHVbtuh9a/JerfD7X8RUTprMbdK4dinnZdx/hzCtHtFxOnPp4egpzWHtJ81CRBkeE6VnMjjzXpxcPwsRBZGBWy9UNJTsANI0AGg2rmytTYmM1aAE+i7TiKhAkiiJYoiSiIopRRF4X9k2+2tp5IUhaSlSTIkHxGo9Y1FdxyPjcHsNEahcloIorht0+5hVzc2zIdjtJaS0twGFjuFUed3VNjqSIB3r7Ts2cRgjmeRdUSa5fTWz4LzWyGJzmeStPJfhqnb83YZcCEhSVLUsyFqHMHWYOXL768vjcLWBtya0KaAKrqSKvuu+5bIMYXNMTW6Xqft08l2WvnFeiilE0RQ0MSsKUkEiYUQCRPQ8q6DnAVeirMTHODiBY50pk1C7STUKUURFESTRQvO4MIUf5T8qKFiPIb+52Pbe/VVUlSFvahERRKULEMHt7ggvsNOlIUElaEqICxCgCRoCN6sZLJH7jiP42UUCltcJt2tWmGkEhAJShKSQ2IQDA/hG3SodI93vEn49d0oBPvcOZfyh5pDmRQWjOkKyrGyhOxHWkcj4/cJGleIU0E+7tG3klDqErQRCkrAUkjoUnQ1DHOYQ5pojmlLNcWcGNXNqpm2CLdXa9uChASlboBHeyidZ84aggbxB9HA8SfBOJJLcKy6nYdyplizNoaLOcM8c5bJX0tz/1AUWkhYylZMZc2mgSTClECOdb8dwknE/8ATt9gjNpyHPz5Dms8OKblqQ6gqv8AJJZJF5cpzJcbaUpTByycxVkU4lXSNN9dCNNa642+YxxudpYoj6A/fyV0L4dY2bjyXXEIA0Aj1aV85Z5q8NA2TqKaQTUIqZzCW3n0vLkqAEDlpEeNaWYp7IzGNl583DIZZxM6700vQ1t62VzWdeikmoRFERRElEXoaKAkopRRElERREURFETOzTObKM0RMaxvE9NTU2apRQSIbSmcoAkkmBEk7n10JJ3QADZPqFKJoiKIiiIoiKIkooSTRAiilBE6HY6Gi5UPAsFYsWU29qjI0kqKU5lK1UoqPeUSTqTUqQrCoUooiKIkoiKIiiIooKy6uAbFTjjq2ypTi1LMrVAKpnKARpJJ1nX1CvSbxnF5QxrqDaGw+e6yHCQkkkbq2wPBmbJoNMCANSTqpR6k1lxOJkxD+0kOquhiZG3K0Kxms6uSmiJKIkAoiWiIoiKIkJoiSiL/2Q==\"  width=\"350\" ></center>\n",
    "<center> Figure 5: Examples of matching cliques. Source: Cour et al. (2005). </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xucXQ_UWmvxj"
   },
   "source": [
    "To illustrate a bit more the idea of imbalance in the structure of $W$, we reproduced the synthetic noise model example of the article from Cour et al. (2005) (figure 2 in the article). The following piece of code aims at implementing the Bistochastic Normalization. Without any further details yet, let's explain the benefit from the method through this simple example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 976
    },
    "colab_type": "code",
    "id": "1t5tfQwyHZyF",
    "outputId": "8b6cdc06-d7cd-4242-a1b8-34114b58481e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining 2 isomorphic graphs with 3 nodes...\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAADQCAYAAAAnDzSKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalization...\n",
      "Time elapsed: 0.067 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAJNCAYAAADd8RrVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################Synthetic noise model example#############################\n",
    "# First, we import packages of interest for this example\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import view_as_blocks\n",
    "import networkx as nx\n",
    "from copy import copy\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# We create a synthetic function to display graph using networkx package\n",
    "def getGraph(nodes, edges, positions):\n",
    "    \"\"\"\n",
    "    :param nodes     : list, labels of nodes\n",
    "    :param edges     : list, list of tuples. A tuple represent any connection (undirected graph).\n",
    "    :param positions : list of tuples, (x, y) coordinates of nodes\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    G = G.to_undirected()\n",
    "    pos = {}\n",
    "    for i, n in enumerate(nodes):\n",
    "      pos[n] = positions[i]\n",
    "    nx.draw(G, pos=pos, with_labels=True, font_weight='bold', node_size=1e3)\n",
    "\n",
    "# We display the 2 graphs of figure 2 (article)\n",
    "print('Defining 2 isomorphic graphs with 3 nodes...\\n')\n",
    "edges_G1 = [['1', '2'], ['1', '3'], ['2', '3']]\n",
    "edges_G2 = [[\"1'\", \"2'\"], [\"1'\", \"3'\"], [\"2'\", \"3'\"]]\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "getGraph(['1', '2', '3'], edges_G1, positions=[(2, 1), (1, 1.5), (1, 0.5)])\n",
    "plt.title('Graph G', fontsize=10)\n",
    "plt.subplot(1, 2, 2)\n",
    "getGraph([\"1'\", \"2'\", \"3'\"], edges_G2, positions=[(0, 1), (1, 1.5), (1, 0.5)])\n",
    "plt.title(\"Graph G'\", fontsize=10)\n",
    "plt.show()\n",
    "    \n",
    "################################################################################\n",
    "\n",
    "t = time.time()\n",
    "print('\\nNormalization...')\n",
    "# Then, we define W_b as a proxy of matrix W inspired from the gray colorscale\n",
    "# from middle image of figure 2 (Cour et al., 2005)\n",
    "W_b = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0.25, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
    "                [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
    "                [0, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "                [0, 0.25, 0, 0, 0, 0.25, 0, 0, 0, 0.25],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 0.25, 0, 0, 0, 0.25, 0, 0, 0, 0.25]])\n",
    "\n",
    "# Now, we briefly define a method to transform W to S\n",
    "def WtoS(W, n1, n2):\n",
    "  \"\"\"\n",
    "  Transform compatibility matrix W to similarity matrix S\n",
    "  :param W  : np.array, compatibility matrix\n",
    "  :param n1 : np.array, number of vertices in first graph\n",
    "  :param n2 : np.array, number of vertices in second graph\n",
    "  :return   : np.array, similarity matrix S\n",
    "  \"\"\"\n",
    "  blocks = view_as_blocks(W,  block_shape=(n1, n1))\n",
    "  S = np.zeros((n1**2, n2**2))\n",
    "  for j in range(n2**2):\n",
    "        S[:, j] = blocks[j//n2, j % n2].flatten('F')\n",
    "  return S\n",
    "\n",
    "# Then, we apply it on W_b\n",
    "S_b = WtoS(W_b[:, 1:10][1:10], 3, 3)\n",
    "S_b = np.c_[np.zeros(S_b.shape[0]), S_b]    \n",
    "S_b = np.r_[[np.zeros(S_b.shape[1])], S_b]\n",
    "\n",
    "# Before implementing bistochastic normalization, we use norm_check\n",
    "# method\n",
    "def norm_check(x):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  s = np.abs(x).sum()\n",
    "  if s > 0:\n",
    "    return x/s\n",
    "  else:\n",
    "    return x\n",
    "      \n",
    "def bistochastic_normalization(W, n1, n2, max_iter=100, tol=1e-4):\n",
    "  \"\"\"\n",
    "  Implement Bistochastic Normalization as described in section 5.2 in Cour et al. (2005)\n",
    "  :param W        : np.array, compatibility matrix\n",
    "  :param n1       : np.array, number of vertices in first graph\n",
    "  :param n2       : np.array, number of vertices in second graph\n",
    "  :param max_iter : int, maximal number of iterations (stopping criteria n°1) \n",
    "  :param tol      : float, precision threshold (stopping criteria n°2) \n",
    "  :return         : np.array, normalized compatibility matrix W\n",
    "  \"\"\"\n",
    "  blocks = view_as_blocks(W, (n1, n1))\n",
    "  S = np.zeros((n1**2, n2**2))\n",
    "  for j in range(n2**2):\n",
    "      S[:, j] = blocks[j//n2, j % n2].flatten('F')\n",
    "  err = np.inf\n",
    "  iter = 0\n",
    "  while iter < max_iter and err > tol:\n",
    "      old_S = copy(S)\n",
    "      S = np.apply_along_axis(norm_check, 1, S)\n",
    "      S = np.apply_along_axis(norm_check, 0, S)\n",
    "      err = np.sum(np.abs(S-old_S)**2)\n",
    "      iter += 1\n",
    "  W_blocks = [[S[:, n2*i+j].reshape((n1, n1)) for i in range(n2)] for j in range(n2)]\n",
    "  return np.block(W_blocks).T\n",
    "  \n",
    "# Now, we apply Bistochastic Normalization on W_b...\n",
    "W_a = bistochastic_normalization(W_b[:, 1:10][1:10], 3, 3) \n",
    "# ... and get S_a\n",
    "S_a = WtoS(W_a, 3, 3)\n",
    "# We also add first row and column of zeros to plot the indices\n",
    "S_a = np.c_[np.zeros(S_a.shape[0]), S_a]    \n",
    "S_a = np.r_[[np.zeros(S_a.shape[1])], S_a]  \n",
    "W_a = np.c_[np.zeros(W_a.shape[0]), W_a]    \n",
    "W_a = np.r_[[np.zeros(W_a.shape[1])], W_a] \n",
    "\n",
    "################################################################################\n",
    "\n",
    "# We define the indices to plot as texts on the images\n",
    "# For W\n",
    "coord_W = [\"(1, 1')\", \"(2, 1')\", \"(3, 1')\",\n",
    "           \"(1, 2')\", \"(2, 2')\", \"(3, 2')\",\n",
    "           \"(1, 3')\", \"(2, 3')\", \"(3, 3')\"]\n",
    "# For S\n",
    "coord_S_x = [\"(1, 1)\", \"(2, 1)\", \"(3, 1)\",\n",
    "             \"(1, 2)\", \"(2, 2)\", \"(3, 2)\",\n",
    "             \"(1, 3)\", \"(2, 3)\", \"(3, 3)\"]\n",
    "\n",
    "coord_S_y = [\"(1', 1')\", \"(1', 2')\", \"(1', 3')\",\n",
    "             \"(2', 1')\", \"(2', 2')\", \"(2', 3')\",\n",
    "             \"(3', 1')\", \"(3', 2')\", \"(3', 3')\"]\n",
    "\n",
    "# And plot the results in a similar fashion than the authors\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# First subplot\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.imshow(1-W_b)\n",
    "for i in range(9):\n",
    "  text = ax.text(0, i+1, coord_W[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "  text = ax.text(i+1, 0, coord_W[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "ax.grid(False)\n",
    "ax.axis('off')\n",
    "ax.set_title('W before normalization')\n",
    "\n",
    "# Second subplot\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.imshow(1-S_b)\n",
    "for i in range(9):\n",
    "  text = ax.text(0, i+1, coord_S_x[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "  text = ax.text(i+1, 0, coord_S_y[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "ax.grid(False)\n",
    "ax.axis('off')\n",
    "ax.set_title('S before normalization')\n",
    "\n",
    "# Third subplot\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.imshow(1-W_a)\n",
    "for i in range(9):\n",
    "  text = ax.text(0, i+1, coord_W[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "  text = ax.text(i+1, 0, coord_W[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "ax.grid(False)\n",
    "ax.axis('off')\n",
    "ax.set_title('W after normalization')\n",
    "\n",
    "# Second subplot\n",
    "ax = fig.add_subplot(2, 2, 4)\n",
    "ax.imshow(1-S_a)\n",
    "for i in range(9):\n",
    "  text = ax.text(0, i+1, coord_S_x[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "  text = ax.text(i+1, 0, coord_S_y[i], ha=\"center\", va=\"center\", color=\"w\", fontsize='x-small')\n",
    "ax.grid(False)\n",
    "ax.axis('off')\n",
    "ax.set_title('S after normalization')\n",
    "print('Time elapsed: {:2.3f} seconds\\n'.format(time.time()-t))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXPzrIT5wsOy"
   },
   "source": [
    "The previous synthetic noise model example consists in defining 2 isomorphic graphs with 3 nodes. Edges 12 and 13 are *uninformative* as they make connections to every other edges of the second graph $G'$. Those connections are caracterized by their similarity score $W_{ii',jj'} = f(A_{ij}, A'_{i'j'})$ which is directly proportional to a noise parameter $\\sigma \\geq 0$. White boxes represent the highest edges compatibility similarity score. As suggested by the authors, the similiarity function $f(\\cdot, \\cdot)$ can be interpreted in two ways:\n",
    "* a similarity between edges $ij \\in E$ and $i'j' \\in E'$\n",
    "* or a compatibility between match hypothesis $ii' \\in M$ and $jj' \\in M$.\n",
    "\n",
    "To this effect, we define the **similarity matrix** $S$ of size $m \\times m' $ as $S_{ij,i'j'} = f(A_{ij}, A'_{i'j'}) = W_{ii', jj'}$ (see figure 2 of the report for a visual interpretation).  In our opinion, $S$ is more suitable for vizualizing the similarity between edges of 2 graphs. Indeed, back to our example, we see from the 2 \"white\" lines of $S$ before normalization that  edges 12 and 13 are effectively quite non informative. So are the edges 1'2' and 1'3'. On the contrary, edges 23 is relatively similar to 2'3' (and not similar at all with the other edges). This is another example where $W$ is particularly unbalanced.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRwKr8A69j-m"
   },
   "source": [
    "\n",
    "<center><img src=\"data:image/jpeg;base64,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\"  width=\"350\" ></center>\n",
    "<center> Figure 4: example of unbalanced matrix $W$ through synthetic noise example. Source: Cour et al. (2005) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMDRA-Ca7FWS"
   },
   "source": [
    "This has a direct consequence on the accuracy of the matching, as shown in figure 4 of this report (right figure). When the noise is zero, white boxes are \"black\", meaning that most of the edges are not connected to one another. Matrix $S$, before normalization, is thus very sparse and has positive potentials only on edges $(1, 1), (1, 1')$;  $(2, 2), (2, 2')$;  $(3, 3), (3, 3')$ but most importantly on edges  $(2, 1), (2', 1')$;  $(3, 1), (3', 1')$ and $(3,2), (3', 2')$. Citing the authors: \"when the noise is small enough, the optimal matching is the desired permutation $p^* = \\{11',22',33'\\}$, with an initial score of 8 for $\\sigma=0$\". The latter computed the score of the second best permutation returned by the brute-force solving of the IQP as a function of noise level. From it, they displayed the difference between the graph matching score of 8 obtained before and the new optimal permutation depending on $\\sigma$. This corresponds to the *margin*. Firstly, we see that the margin is stricly decreasing in $\\sigma$ without the application of bistochastic normalization. In fact, for $\\sigma > \\sigma_0 \\approx 1.6$, $p*$ is no longer optimal because the non informative edges outweight matrix $W$ and thus strongly affect the resulting optimal solution $x^*$ found. We talk about *spurious* connections to qualify the connections between edges (in $W$) which are not accurate and considerably decrease the influence of the other distinctive edges. According to the authors, this is the \"main source of confusion for graph matching\" and bistochastic normalization (BN) aims at fixing it. On our simplistic example, it drastically improves the optimal permutation returned by the algorithm and yield a matching which is robust to large noises put in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSpE1pXA_u8K"
   },
   "source": [
    "When we talk about *influence*, we can refer to the similarity matrix $S$. Indeed, the previous example showed the benefit of bistochastic normalization on rebalancing the influence of the connections between edges. In particular, the 2 columns of high influence in $S$ have globally been reduced by half in our example, whereas accurate connections weight have been increased. As a conclusion, spurious connections have been removed and informative ones enhanced. \n",
    "\n",
    "Hence $S$ measures the influence of those edges in the compatibility matrix, and, as we said,  is more suitable for analysing it. \n",
    "\n",
    "Bistochastic normalisation thus makes full use of matrix $S$ in order to decrease the influence of *non discriminative* edges and, on the contrary, increase the influence of a *discriminative* which has a small number of good matches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_Ycrs6-BH2I"
   },
   "source": [
    "The principle of the bistochastic normalization is based on our previous observations: we would like, for SMAC and other relaxation methods to perform better, vertex and edge to match to a small number of vertices and edges respectively. In practise, this constraint would be very hard to apply. Nevertheless, Cour et al. (2005) suggest to normalize $S$ in such a way that to mimick this constraint. This corresponds to requiring $S$ to have each row and column \"sum to 1\", i.e., be bistochastic. However, $S$ can be rectangular of size $m \\times m'$ and accordingly can not be a classical permutation matrix whose rows and columns sum to 1 (and mostly can't be a square matrix). That's why Cour et al. define a matrix $B$ of size $m \\times m'$ as being **rectangular bistochastic** if it satisfies:\n",
    "$$B \\mathbf{1}_{m'} = \\mathbf{1}_m \\hspace{1cm} \\text{and} \\hspace{1cm} B \\mathbf{1}_{m} = \\frac{m}{m'}\\mathbf{1}_{m'}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ba3BOp5HvnE"
   },
   "source": [
    "The second contribution of the article is the following theorem:\n",
    "\n",
    "___\n",
    "___\n",
    "\n",
    "Under the condition $S >0$ elementwise, the problem consisting in finding $(D, D')$ such that $D$ and $D'$ are diagonal matrices of size $m, m'$ respectively and $DSD'$ is rectangular bistochastic, has a unique solution, $(D^*,D'^*)$ up to a scale factor. $D^*$ and $D'^*$ can be found by iteratively normalizing the rows and columns of $S$ as follows:\n",
    "\n",
    "\n",
    "1.   Input: compatibility matrix $W$ of size $nn' \\times nn'$\n",
    "\n",
    "2.  Convert $W$ to $S$ through $S_{ij,i'j'}=W_{ii',jj'}$\n",
    "\n",
    "3.   Repeat until convergence:\n",
    "> 3.1 Normalize rows of $S$: $S_{ij,i'j}'^{t+1} := S_{ij,i'j'}^{t} \\Big/  \\sum_{k'l'} S_{ij,k'l'}^{t}$\n",
    "> 3.2 Normalize columns of $S$: $S_{ij,i'j}'^{t+2} := S_{ij,i'j'}^{t+1} \\Big/  \\sum_{kl} S_{kl,i'j'}^{t+1}$\n",
    "\n",
    "4. Convert back $S$ to $W$\n",
    "\n",
    "5. Output: $W$ \n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXgcYlLxLn9j"
   },
   "source": [
    "Let's now give a proof of the previous theorem. First, let's define the Kronecker product of a matrix $A$ of size $m \\times n$ with $B$ of size $p \\times q$ as the tensor product between $A$ and $B$. Namely, $$A \\otimes B = \\begin{pmatrix} a_{11} B & \\cdots & a_{1n}B \\\\ \\vdots & \\ddots & \\vdots \\\\ a_{m1} B & \\cdots & a_{mn} B \\end{pmatrix}$$\n",
    "We now transform $S$ into a square matrix of size $mm' \\times mm'$: $\\bar{S} = S  \\otimes  \\mathbf{1}_{m' \\times m}$ where $ \\mathbf{1}_{m' \\times m}$ is a matrix of ones of size $m' \\times m$. Moreover, as $W$ is nonngeative, $\\bar{S}$ is also nonnegative (elementwise). Cour et al. then use a very useful theorem in graph theory which was proposed and proved by Sinkhorn and Knopp in \"Concerning nonegative matrices and boudly stochastic matrices\" (1967). They showed the following result:\n",
    "\n",
    "*let $A$ be a nonnegative square matrix. A necessary and sufficient condition that there exists a doubly stochastic matrix $B$ of the form $D_1 A D_2$ where $D_1$ and $D_2$ are diagonal matrices with positive main diagonals is that $A$ has total support. If $B$ exists then it is unique. Also, $D_1$ and $D_2$ are unique up to a sclaiar multiple if and only if $A$ is fully indecomposable. A necessary and sufficient condition that the iterative process of alternately normalizaing the rows and columns of $A$ will converge to a doubly stocahstic limit is that $A$ has support. If $A$ has total support, this limit is the described matrix $D_1AD_2$. If $A$ has support which is not total, this limit cannot be of the form $D_1AD_2$.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrNATon7L7v5"
   },
   "source": [
    "Cour et al. apply this theorem to the square nonnegative matrix $\\bar{S}$. Under the hypothesis that $S>0$ elementwise, $\\bar{S}$ is also strictly positive elementwise. This allows to apply Sinkhorn et Knopp's theorem. Indeed, first, a matrix $A$ has total support if every $A_{ij} \\neq 0$ belongs to some positive diagonal of $A$. Or, $A$ does not have total support if and only if there exists $A_{ij} \\neq 0$ such that the submatrix obtained by deleting row $i$ and column $j$ has no positive diagonal. Here, all elements of $\\bar{S}$ are strictly positive, so the latter matrix has total support. Then, a matrix $A$ is said to be  irreductible if there exists *no* permutation matrix $P$ such that $P^{-1}AP$ is equal to a block upper triangular matrix. In other words, a matrix is irreductible if it is not reductible. A useful theorem proved in, for example, A. Horn and R. Johnson, \"Matrix analysis, second edition\" (2013), theorem 6.2.23 p. 403,  is the following characterization of irreductible matrix: given a matrix $A \\in M_n(\\mathbb{R}$ nonnegative, $A$ is irreductible if and only if the matrix $(I_n + |A|)^{n-1}$ is strictly positive. In fact, here, $\\bar{S}$ is strictly positive so, obviously, the latter condition is true. Hence, $\\bar{S}$ has total support and is irreductible: Sinkhorn et Knopp's conditions are satisfied.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1h3BkwWSt7t"
   },
   "source": [
    "Thus, there exists $2$ diagonal matrices of size $m \\times m'$ such that $D_1 \\bar{S} D_2$ is bistochastic. Now, let's remark that, as said by the authors, \"normalizing rows and columns of $\\bar{S}$ preserves kronecker structure\", namely, for two diagonal matrices $(D, D')$ of size $m, m'$ respectively :\n",
    "$$\\bar{D} \\bar{S} \\bar{D}' = (D \\otimes \\mathbf{1}_{m' \\times m'}) (S \\otimes \\mathbf{1}_{m' \\times m}) (D' \\otimes \\mathbf{1}_{m \\times m'}) = mm' DSD' \\otimes \\mathbf{1}_{m' \\times m})$$ Let's briefly proves it. As $D$ and $D'$ are diagonal matrix, $\\bar{D}$ and $\\bar{D}'$ are block diagonal matrix of size $m \\times m'$ with blocks of size $m' \\times m'$ and $m \\times m$ respectively. Thus, $\\bar{D} \\bar{S} \\bar{D}'$ is a block full matrix with blocks of size $m' \\times m$ equal to (we do write matrices of ones to avoid confusion):\n",
    "$$\\begin{pmatrix}\n",
    "D_{11} S_{11,1'1'} D'_{1'1'} & ... & D_{11} S_{11,m'm'} D'_{m'm'} \\\\\n",
    "D_{22} S_{21,1'1'} D'_{1'1'} & ... & D_{22}S_{21,m'm'} D'_{m'm'} \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "\\cdots & D_{ii} S_{ij,i'j'} D'_{j'j'} & ...  \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "D_{mm} S_{mm,1'1'} D'_{1'1'} & ... & D_{mm} S_{mm,m'm'} D'_{m'm'} \\\\\n",
    "\\end{pmatrix}$$\n",
    "where the general block term is equal to (exact formula with matrices of ones):\n",
    "$$D_{ii}S_{ij,i'j'}D'_{j'j'}\\mathbf{1}_{m' \\times m'} \\cdot  \\mathbf{1}_{m' \\times m} \\cdot \\mathbf{1}_{m \\times m'}$$ Simple calculus then shows that:\n",
    "$$\\mathbf{1}_{m' \\times m'} \\cdot  \\mathbf{1}_{m' \\times m} \\cdot \\mathbf{1}_{m \\times m'} = mm' \\mathbf{1}_{m' \\times m}$$ and thus $\\bar{D} \\bar{S} \\bar{D}'$ is a block matrix with general block term equal to:\n",
    "$$mm'  D_{ii}S_{ij,i'j'}D'_{j'j'} \\mathbf{1}_{m' \\times m}$$ which corresponds exactly to $mm' DSD' \\otimes \\mathbf{1}_{m' \\times m}$ and concludes the proof. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h8qN15pTjYA"
   },
   "source": [
    "Now the authors state the following: * $(m^2 D, m' D')$ is solution for $S$ if and only if $(\\bar{D}, \\bar{D}')$ is solution for $\\bar{S}$.* Where \"solution for $S$\" means that, for example, $m^2 m' DSD'$ is rectangular bistochastic as defined earlier. Let's prove it.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "baG1ISoJXW2j"
   },
   "source": [
    "* Suppose that $m^2 m' DSD'$ is rectangular bistochastic.\n",
    "We first want to show that $\\bar{D} \\bar{S} \\bar{D}' \\mathbf{1}_{mm'} = \\mathbf{1}_{mm'} $. Based on our latter result, \n",
    "$$\\bar{D} \\bar{S} \\bar{D}' \\mathbf{1}_{mm'} = mm' DSD' \\otimes \\mathbf{1}_{m' \\times m} \\cdot \\mathbf{1}_{mm'}$$ Written in matrix form, the right-hand side term is a follows:\n",
    "\n",
    " \n",
    " \\begin{equation*}\n",
    "  mm' \\times  \\begin{array}{c@{\\!\\!\\!}l}\n",
    "  \\left( \\begin{array}[c]{ccccc}\n",
    "    md_{11} S_{11,1'1'} d'_{1'1'} &+ ... +& md_{11} S_{11,m'm'} d'_{m'm'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "md_{11} S_{11,1'1'} d'_{1'1'} &+ ... +& md_{11} S_{11,m'm'} d'_{m'm'}  \\\\\n",
    "md_{22} S_{21,1'1'} d'_{1'1'} &+ ... +& md_{22} S_{21,m'm'} d'_{m'm'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "md_{22} S_{21,1'1'} d'_{1'1'} &+ ... +& md_{22} S_{21,m'm'} d'_{m'm'}  \\\\ \n",
    "md_{mm} S_{mm,1'1'} d'_{1'1'} &+ ... +& md_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "md_{mm} S_{mm,1'1'} d'_{1'1'} &+ ... +& md_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "  \\end{array}  \\right)\n",
    "\\end{array} \\hspace{0.5cm} =  \\hspace{0.5cm} m^2m' \\times  \\begin{array}{c@{\\!\\!\\!}l}\n",
    "  \\left( \\begin{array}[c]{ccccc}\n",
    "    d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +& d_{11} S_{11,m'm'} d'_{m'm'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +& d_{11} S_{11,m'm'} d'_{m'm'}  \\\\\n",
    "d_{22} S_{21,1'1'} d'_{1'1'} &+ ... +& d_{22} S_{21,m'm'} d'_{m'm'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{22} S_{21,1'1'} d'_{1'1'} &+ ... +& d_{22} S_{21,m'm'} d'_{m'm'}  \\\\ \n",
    "d_{mm} S_{mm,1'1'} d'_{1'1'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{mm} S_{mm,1'1'} d'_{1'1'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "  \\end{array}  \\right)\n",
    "&\n",
    " \\begin{array}[c]{@{}l@{\\,}l}\n",
    "\\left. \\begin{array}{c} \\vphantom{0} \\\\ \\vphantom{\\vdots}\n",
    "   \\\\ \\vphantom{0}  \\end{array} \\right\\} & \\text{$m'$ times} \\\\\n",
    "\\left. \\begin{array}{c} \\vphantom{0}\n",
    "  \\\\ \\vphantom{\\vdots} \\\\ \\vphantom{0} \\end{array} \\right\\} & \\text{$m'$ times} \\\\\n",
    "\\left. \\begin{array}{c} \\vphantom{0}\n",
    "  \\\\ \\vphantom{\\vdots} \\\\ \\vphantom{0} \\end{array} \\right\\} & \\text{$m'$ times}\n",
    "\\end{array}\n",
    "\\end{array} \n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6mkaojFYmZF"
   },
   "source": [
    "But, we made the hypothesis that $m^2m'DSD'$ is rectangular bistochastic. Thus, $m'm^2DSD' \\mathbf{1}_m = \\mathbf{1}_m$ and it directly implies that each element of the above vector is equal to 1. Finally, we thus showed that $\\bar{D} \\bar{S} \\bar{D}' \\mathbf{1}_{mm'} = \\mathbf{1}_{mm'} $. Now, we need to prove that $\\Big(\\bar{D} \\bar{S} \\bar{D}' \\Big)^\\top\\mathbf{1}_{mm'} = \\mathbf{1}_{mm'} $. One may recall that a second implication of our hypothesis is that $m'm^2\\Big(DSD' \\Big)^\\top\\mathbf{1}_{m'} = (m/m') \\mathbf{1}_{m'}$ which is the same as $m'^2m\\Big(DSD' \\Big)^\\top\\mathbf{1}_{m'} = \\mathbf{1}_{m'}$. This second formulation is very similar to that of the other condition. In fact, if we apply the same reasoning as before with transposed matrix, we exactly fall back to the same proof as above. Once we proved the first characterization of the permutation matrix $\\bar{D} \\bar{S} \\bar{D}'$, the symmetric one is strainghtforward. Hence, we've just shown the left to right implication. It means that, if $(m^2 D, m'D')$ is a solution for normalizing $S$, then $(\\bar{D}, \\bar{D}')$ is a solution for normalizing $\\bar{S}$. Using the uniqueness of the decomposition into a bistochastic square matrix of $\\bar{S}$ according to Sinkhorn and Knopp's theorem, we have that $D_1=\\bar{D}$ and $D_2=\\bar{D}'$ up to a numerical constant that we omit here for more clarity. Now, let's prove the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xgmn_4X9XX3i"
   },
   "source": [
    "* Suppose that $\\bar{D} \\bar{S} \\bar{D}' $ is a square bistochastic matrix of size $mm' \\times mm'$.\n",
    "We first want to show that $m'm^2 DSD' \\mathbf{1}_{m} = \\mathbf{1}_{m} $. Once again, we base our proof on our first result, \n",
    "$$\\bar{D} \\bar{S} \\bar{D}' = mm' DSD' \\otimes \\mathbf{1}_{m' \\times m}$$ Our hypothesis implies that:\n",
    "$$\\bar{D} \\bar{S} \\bar{D}' \\mathbf{1}_{mm'} = mm' DSD' \\otimes \\mathbf{1}_{m' \\times m} \\cdot \\mathbf{1}_{mm'} = \\mathbf{1}_{mm'} $$\n",
    "\n",
    "Written in matrix form, this is equivalent to:\n",
    "\n",
    " \\begin{equation*}\n",
    "  m^2m' \\times  \\begin{array}{c@{\\!\\!\\!}l}\n",
    "  \\left( \\begin{array}[c]{ccccc}\n",
    "    d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +& d_{11} S_{11,m'm'} d'_{m'm'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +& d_{11} S_{11,m'm'} d'_{m'm'}  \\\\\n",
    "d_{22} S_{21,1'1'} d'_{1'1'} &+ ... +& d_{22} S_{21,m'm'} d'_{m'm'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{22} S_{21,1'1'} d'_{1'1'} &+ ... +& d_{22} S_{21,m'm'} d'_{m'm'}  \\\\ \n",
    "d_{mm} S_{mm,1'1'} d'_{1'1'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{mm} S_{mm,1'1'} d'_{1'1'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "  \\end{array}  \\right)\n",
    "& = & \\left( \\begin{array}[c]{c}\n",
    "1  \\\\\n",
    "\\vdots \\\\\n",
    "1  \\\\\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "1 \\\\ \n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\end{array} \\right)\n",
    " \\begin{array}[c]{@{}l@{\\,}l}\n",
    "\\left. \\begin{array}{c} \\vphantom{0} \\\\ \\vphantom{\\vdots}\n",
    "   \\\\ \\vphantom{0}  \\end{array} \\right\\} & \\text{$m'$ times} \\\\\n",
    "\\left. \\begin{array}{c} \\vphantom{0}\n",
    "  \\\\ \\vphantom{\\vdots} \\\\ \\vphantom{0} \\end{array} \\right\\} & \\text{$m'$ times} \\\\\n",
    "\\left. \\begin{array}{c} \\vphantom{0}\n",
    "  \\\\ \\vphantom{\\vdots} \\\\ \\vphantom{0} \\end{array} \\right\\} & \\text{$m'$ times}\n",
    "\\end{array}\n",
    "\\end{array} \n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51QPSpM0XXm_"
   },
   "source": [
    "We clearly see that, on the $mm'$ conditions above, there are exactly $m$ unique conditions, more specifically:\n",
    "\n",
    " \\begin{equation*}\n",
    "  m^2m' \\times  \\begin{array}{c@{\\!\\!\\!}l}\n",
    "  \\left( \\begin{array}[c]{ccccc}\n",
    "    d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +& d_{11} S_{11,m'm'} d'_{m'm'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{mm} S_{mm,1'1'} d'_{1'1'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "  \\end{array}  \\right)\n",
    "& = & \\left( \\begin{array}[c]{c}\n",
    "1  \\\\\n",
    "\\vdots \\\\\n",
    "1  \\\\\n",
    "\\end{array} \\right)\n",
    " \\begin{array}[c]{@{}l@{\\,}l}\n",
    "\\left. \\begin{array}{c} \\vphantom{0}\n",
    "  \\\\ \\vphantom{\\vdots} \\\\ \\vphantom{0} \\end{array} \\right\\} & \\text{$m$ times}\n",
    "\\end{array}\n",
    "\\end{array} \n",
    "\\end{equation*}\n",
    "which is equivalent to writing:  $m^2 m' DSD \\mathbf{1}_m = \\mathbf{1}_m$. We thus proved the first characterization of $(D, D')$ being a solution for $S$. The second is strainghtforward once we've done that. Indeed, we now want to prove that $m^2 m' \\Big(DSD\\Big)^\\top \\mathbf{1}_{m'} = \\frac{m}{m'}\\mathbf{1}_{m'}$ which is equivalent to showing that $m m'^2 \\Big(DSD\\Big)^\\top \\mathbf{1}_{m'} = \\mathbf{1}_{m'}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Fb08J5AXXZz"
   },
   "source": [
    "Our hypothesis also implies that:\n",
    "$$\\Big(\\bar{D} \\bar{S} \\bar{D}'\\Big)^\\top \\mathbf{1}_{mm'} = mm' \\Big(DSD' \\otimes \\mathbf{1}_{m' \\times m} \\Big)^\\top \\cdot \\mathbf{1}_{mm'} = \\mathbf{1}_{mm'} $$\n",
    "\n",
    "Similarly to the previous derivations, we can write this in matrix form as:\n",
    "\n",
    " \\begin{equation*}\n",
    "  m'^2m \\times  \\begin{array}{c@{\\!\\!\\!}l}\n",
    "  \\left( \\begin{array}[c]{ccccc}\n",
    "    d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +&  d_{mm} S_{mm,1'1'} d'_{1'1'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "    d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +&  d_{mm} S_{mm,1'1'} d'_{1'1'}  \\\\ \n",
    " \\vdots & \\cdots & \\vdots\\\\   \n",
    "d_{11} S_{11,m'm'} d'_{m'm'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{11} S_{11,m'm'} d'_{m'm'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "  \\end{array}  \\right)\n",
    "& = & \\left( \\begin{array}[c]{c}\n",
    "1  \\\\\n",
    "\\vdots \\\\\n",
    "1  \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\end{array} \\right)\n",
    " \\begin{array}[c]{@{}l@{\\,}l}\n",
    "\\left. \\begin{array}{c} \\vphantom{0} \\\\ \\vphantom{\\vdots}\n",
    "   \\\\ \\vphantom{0}  \\end{array} \\right\\} & \\text{$m$ times} \\\\ \\\\\n",
    "\\left. \\begin{array}{c} \\vphantom{0}\n",
    "  \\\\ \\vphantom{\\vdots} \\\\ \\vphantom{0} \\end{array} \\right\\} & \\text{$m$ times} \n",
    "\\end{array}\n",
    "\\end{array} \n",
    "\\end{equation*}\n",
    "Which represent $mm'$ redundant conditions but only $m'$ unique conditions:\n",
    " \\begin{equation*}\n",
    "  m'^2m \\times  \\begin{array}{c@{\\!\\!\\!}l}\n",
    "  \\left( \\begin{array}[c]{ccccc}\n",
    "    d_{11} S_{11,1'1'} d'_{1'1'} &+ ... +&  d_{mm} S_{mm,1'1'} d'_{1'1'}  \\\\ \n",
    "\\vdots & \\cdots & \\vdots\\\\\n",
    "d_{11} S_{11,m'm'} d'_{m'm'} &+ ... +& d_{mm} S_{mm,m'm'} d'_{m'm'}  \\\\\n",
    "  \\end{array}  \\right)\n",
    "& = & \\left( \\begin{array}[c]{c}\n",
    "1  \\\\\n",
    "\\vdots \\\\\n",
    "1  \\\\\n",
    "\\end{array} \\right)\n",
    " \\begin{array}[c]{@{}l@{\\,}l}\n",
    "\\left. \\begin{array}{c} \\vphantom{0} \\\\ \\vphantom{\\vdots}\n",
    "   \\\\ \\vphantom{0}  \\end{array} \\right\\} & \\text{$m'$ times}\n",
    "\\end{array}\n",
    "\\end{array} \n",
    "\\end{equation*} and is strictly equivalent to the more compact formulation: $m m'^2 \\Big(DSD\\Big)^\\top \\mathbf{1}_{m'} = \\mathbf{1}_{m'}$ and concludes the proof of the validity of bistochastic rectangular normalization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qzm4h8bzXXNY"
   },
   "source": [
    "Cour et al. here proove an important result which can be a generalization of Sinkhorn et Knopp's theorem to positive rectanguler matrix : if a matrix is positive rectangular, then, the algorithm which consists in normalizing successively the rows and columns of $S$ makes $S$ converge to rectangular bistochastic matrix which can be decomposed as $DSD'$ with $D, D'$ of size $m, m'$ respectively and obtained through the process of normalization. To come back to the proof, the fact that normalizing rows ans columns of $\\bar{S}$ preserves the kronecker structure is essential. To sum up, we showed that:\n",
    "\n",
    "1. $\\bar{S}$ can be decomposed as a bistochastic square matrix $D_1 \\bar{S} D_2$ by normalizing successively the rows and columns of $\\bar{S}$\n",
    "2. Then, normalizing rows ans columns of $\\bar{S}$ preserves the kronecker structure. It means that $(D, D')$ and $(\\bar{D}, \\bar{D'})$ are equivalent. In a sens that normalizing $\\bar{S}$ in such a way leads to a decomposition pair $(\\bar{D}, \\bar{D'})$ that can related to the decomposition pair $(D, D')$ obtained by normalizing $S$, thanks to kronecker strcture and up to a scale factor.\n",
    "3. Uniqueness of the decomposition of $\\bar{S}$ implies that $(D_1, D_2) = (\\bar{D}, \\bar{D'})$ thanks to Sinkhorn et Knopp's theorem. \n",
    "\n",
    "As a conclusion, the bistochastic normalization algorithm will converge to a bistochastic rectangular matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "krFS4W0CL9SE"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried the described algorithms with one-to-one matching problems for randomly generated graph with the addition of synthetic noise. We proceeded as follow:\n",
    "* Select a number of nodes $n$ and a number of edge $m$ for each graph G1 and G2\n",
    "* Randomly draw $m$ edges among the $n(n-1)/2$ possibilities (undirected graphs) for G1\n",
    "* Randomly draw a permutation $P$ of the vertices of the G1, such as each edge $(i, j)$ of G1 gives the edge $(P(i), P(j))$ for G2.\n",
    "* Assign independant attributes to each edge/vertice of G1 according to a probability distribution $Q$\n",
    "* Assign the same attribute for the corresponding edge/vertice of G2 with addition of a synthetic noise drawn according to a distribution $S_v$ for the vertices, then $S_e$ for the edges (which can depend on the realisation of the noise for the vertices. This gives the generic form of the attributes matrix:\n",
    "$$\n",
    "A_{P(i)P(i)} = A_{i, i}+ s_v(i)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "A_{P(i)P(j)} = A_{i, j}+ s_e(i, j)\n",
    "$$\n",
    "With $s_v(i) \\sim S_v $ $\\forall i$ and $s_e(i, j) \\sim S_e(. |s_v(i), s_v(j))$ $ \\forall (i, j)$.\n",
    "\n",
    "As we saw in the first section, with all these elements we are able to compute the compatibility matrix $W$. For this, we only need to properly define a matching function $D_M: (x,y) \\rightarrow D_M(x,y)\\in \\mathbb{R}$. For each problem we defined we tested two versions of the algorithms: the first one using the \"raw\" $W$ and the second one using the bistochastic normalization, so we could compare the two methods.\n",
    "\n",
    "Our graph generation algorithms are below, along with a simple exponential distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eKLnNRYePiJR",
    "outputId": "2e9786b5-625d-4ae5-eb06-6e69a053cfe1"
   },
   "outputs": [],
   "source": [
    "def generate_random_graph(n, m, draw_attribute=np.random.uniform):\n",
    "    \"\"\"\n",
    "    :param n: number of vertices\n",
    "    :param m: number of edges\n",
    "    :param draw_attribute: Distribution for the parameter\n",
    "    :return: tuple (n, set of edges, attribute matrix A)\n",
    "    \"\"\"\n",
    "    edge_set = list(combinations(np.arange(n), 2))\n",
    "    edges_indices = np.random.choice(len(edge_set), replace=False, size=m)\n",
    "    edges = [edge_set[i] for i in edges_indices]\n",
    "    A = np.zeros((n, n))\n",
    "    for e in edges:\n",
    "        A[e[0], e[1]] = draw_attribute()\n",
    "    A = A+A.T\n",
    "    A += np.diag(draw_attribute(size=n))\n",
    "    return n, edges, A\n",
    "\n",
    "\n",
    "def get_perturbed_graph(graph, noise_level, draw_noise=np.random.uniform):\n",
    "    n, E, A = graph\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    Ep = []\n",
    "    Ap = np.zeros(A.shape)\n",
    "    for e in E:\n",
    "        new_e = (indices[e[0]], indices[e[1]])\n",
    "        Ep.append(new_e)\n",
    "        Ap[new_e[0], new_e[1]] = A[e[0], e[1]] + draw_noise(0, noise_level)\n",
    "    Ap = Ap + Ap.T\n",
    "    for i, x in enumerate(indices):\n",
    "        Ap[x, x] = A[i, i] + draw_noise(0, noise_level)\n",
    "    return n, Ep, Ap, indices\n",
    "\n",
    "\n",
    "def exp_dist(x, y):\n",
    "    return np.exp(-np.sum(np.abs(x-y)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtfVks1_slAD"
   },
   "source": [
    "Before further describing our experiments, we can detail the metrics that can be used to evaluate the algorithms. We were inspired by the different figures proposed in the original paper, and implemented:\n",
    "* A score computation, that provide the average percentage of correct matches for a given algorithm/experiment. We also added a little variant that provides the ratio of perfectly matched graph. These scores are obtained by considering the \"ground truth\" permutation used to sample G2 as the best matching. Not that depending of the noise and edge structure this may not actually be the best matching regarding to the data, but for reasonable noise it is generally the case.\n",
    "* A regret indicator by computing the average difference between the ground truth objective $x_P^T W x_P$ and the objective attained by the algorithm $x_{opt}^T W x_{opt}$. The idea is to approximate the indicator $\\mathbb{E}_{Q, S_v, S_e}(x_P^T W x_P-x_{opt}^T W x_{opt})$ for a given problem type. We could then compare these indicators for each algorithm and for different noise levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further description of our experiments and results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiments we mixed uniform and gaussian distributions for the attributes of G1 and the noise of G2. \n",
    "\n",
    "The attributes were distributed either according to a uniform $\\mathcal{U}([0,1])$ or a standard Gaussian $\\mathcal{N}(0, 1)$.\n",
    "\n",
    "The additional noise were always added with 0 means, such as the distribution can be summarized by only one parameter $\\sigma$: $n \\sim \\mathcal{U}([-\\sigma/2,\\sigma/2])$ or $n \\sim \\mathcal{N}(0, \\sigma^2)$. From now we will generally talk of \"a noise level of $\\sigma$\" in both cases for convenience, even if they do not represent the same quantity in practice ($V(n)=\\sigma^2$ for the gaussian and $V(n)= \\sigma^2/12$ for uniform).\n",
    "The functions below can generate these kind of graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_graph(n, m, draw_attribute=np.random.uniform):\n",
    "    \"\"\"\n",
    "    :param n: number of vertices\n",
    "    :param m: number of edges\n",
    "    :param draw_attribute: Distribution for the parameter\n",
    "    :return: tuple (n, set of edges, attribute matrix A)\n",
    "    \"\"\"\n",
    "    edge_set = list(combinations(np.arange(n), 2))\n",
    "    edges_indices = np.random.choice(len(edge_set), replace=False, size=m)\n",
    "    edges = [edge_set[i] for i in edges_indices]\n",
    "    A = np.zeros((n, n))\n",
    "    for e in edges:\n",
    "        A[e[0], e[1]] = draw_attribute()\n",
    "    A = A+A.T\n",
    "    A += np.diag(draw_attribute(size=n))\n",
    "    return n, edges, A\n",
    "\n",
    "\n",
    "def get_perturbed_graph(graph, noise_param=(-1, 1), draw_noise=np.random.uniform):\n",
    "    \"\"\"\n",
    "    :param graph: First graph G1\n",
    "    :param noise_param: Parameters of the distribution of the noise \n",
    "    :param draw_noise: noise distribution \n",
    "    :return: Perturbed permutation of the initial graph\n",
    "    \"\"\"\n",
    "    n, E, A = graph\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    Ep = []\n",
    "    Ap = np.zeros(A.shape)\n",
    "    for e in E:\n",
    "        new_e = (indices[e[0]], indices[e[1]])\n",
    "        Ep.append(new_e)\n",
    "        Ap[new_e[0], new_e[1]] = A[e[0], e[1]] + draw_noise(*noise_param)\n",
    "    Ap = Ap + Ap.T\n",
    "    for i, x in enumerate(indices):\n",
    "        Ap[x, x] = A[i, i] + draw_noise(*noise_param)\n",
    "    return n, Ep, Ap, indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CS_FILIOT_BAUDRY.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
